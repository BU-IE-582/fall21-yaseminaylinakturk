{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb454d1",
   "metadata": {},
   "source": [
    "# IE582 HW3-Yasemin Aylin Akturk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b13551",
   "metadata": {},
   "source": [
    "For the codes and R-files please check: https://github.com/BU-IE-582/fall21-yaseminaylinakturk/tree/gh-pages/HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ad1a8",
   "metadata": {},
   "source": [
    "# Task 1 – On the use of distance information for UwaveGesture Recognition Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de68050",
   "metadata": {},
   "outputs": [],
   "source": [
    "klasor =  \"C:/Users/y.akturk/Documents/\"\n",
    "setwd(klasor)\n",
    "library(\"caret\")\n",
    "library(\"kknn\")\n",
    "library(\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae26e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_acc <- read.csv2(\"uWaveGestureLibrary_X_TRAIN.csv\", header = F, fileEncoding = 'UTF-8-BOM')\n",
    "y_acc <- read.csv2(\"uWaveGestureLibrary_Y_TRAIN.csv\", header = F, fileEncoding = 'UTF-8-BOM')\n",
    "z_acc <- read.csv2(\"uWaveGestureLibrary_Z_TRAIN.csv\", header = F, fileEncoding = 'UTF-8-BOM')\n",
    "\n",
    "test_x_acc <- read.csv2(\"uWaveGestureLibrary_X_TEST.csv\", header = F, fileEncoding = 'UTF-8-BOM')\n",
    "test_y_acc <- read.csv2(\"uWaveGestureLibrary_Y_TEST.csv\", header = F, fileEncoding = 'UTF-8-BOM')\n",
    "test_z_acc <- read.csv2(\"uWaveGestureLibrary_Z_TEST.csv\", header = F, fileEncoding = 'UTF-8-BOM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c240db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename col names\n",
    "\n",
    "colnames (x_acc)[1] = c(\"Ges_Class\")\n",
    "colnames (y_acc)[1] = c(\"Ges_Class\")\n",
    "colnames (z_acc)[1] = c(\"Ges_Class\")\n",
    "\n",
    "\n",
    "colnames (test_x_acc)[1] = c(\"Ges_Class\")\n",
    "colnames (test_y_acc)[1] = c(\"Ges_Class\")\n",
    "colnames (test_z_acc)[1] = c(\"Ges_Class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feeecb75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Ges_Class</th><th scope=col>V2</th><th scope=col>V3</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>6    </td><td>-0.30</td><td>-0.30</td></tr>\n",
       "\t<tr><td>5    </td><td> 1.63</td><td> 1.63</td></tr>\n",
       "\t<tr><td>5    </td><td> 0.66</td><td> 0.66</td></tr>\n",
       "\t<tr><td>3    </td><td> 0.01</td><td> 0.01</td></tr>\n",
       "\t<tr><td>4    </td><td> 1.29</td><td> 1.29</td></tr>\n",
       "\t<tr><td>8    </td><td>-0.48</td><td>-0.48</td></tr>\n",
       "\t<tr><td>7    </td><td> 1.47</td><td> 1.47</td></tr>\n",
       "\t<tr><td>4    </td><td> 0.31</td><td> 0.31</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " Ges\\_Class & V2 & V3\\\\\n",
       "\\hline\n",
       "\t 6     & -0.30 & -0.30\\\\\n",
       "\t 5     &  1.63 &  1.63\\\\\n",
       "\t 5     &  0.66 &  0.66\\\\\n",
       "\t 3     &  0.01 &  0.01\\\\\n",
       "\t 4     &  1.29 &  1.29\\\\\n",
       "\t 8     & -0.48 & -0.48\\\\\n",
       "\t 7     &  1.47 &  1.47\\\\\n",
       "\t 4     &  0.31 &  0.31\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Ges_Class | V2 | V3 |\n",
       "|---|---|---|\n",
       "| 6     | -0.30 | -0.30 |\n",
       "| 5     |  1.63 |  1.63 |\n",
       "| 5     |  0.66 |  0.66 |\n",
       "| 3     |  0.01 |  0.01 |\n",
       "| 4     |  1.29 |  1.29 |\n",
       "| 8     | -0.48 | -0.48 |\n",
       "| 7     |  1.47 |  1.47 |\n",
       "| 4     |  0.31 |  0.31 |\n",
       "\n"
      ],
      "text/plain": [
       "  Ges_Class V2    V3   \n",
       "1 6         -0.30 -0.30\n",
       "2 5          1.63  1.63\n",
       "3 5          0.66  0.66\n",
       "4 3          0.01  0.01\n",
       "5 4          1.29  1.29\n",
       "6 8         -0.48 -0.48\n",
       "7 7          1.47  1.47\n",
       "8 4          0.31  0.31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Ges_Class</th><th scope=col>V2</th><th scope=col>V3</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>6    </td><td>-2.12</td><td>-2.12</td></tr>\n",
       "\t<tr><td>5    </td><td> 0.67</td><td> 0.67</td></tr>\n",
       "\t<tr><td>5    </td><td>-0.19</td><td>-0.19</td></tr>\n",
       "\t<tr><td>3    </td><td> 0.37</td><td> 0.37</td></tr>\n",
       "\t<tr><td>4    </td><td>-0.40</td><td>-0.40</td></tr>\n",
       "\t<tr><td>8    </td><td>-1.08</td><td>-1.08</td></tr>\n",
       "\t<tr><td>7    </td><td> 1.26</td><td> 1.26</td></tr>\n",
       "\t<tr><td>4    </td><td>-0.33</td><td>-0.33</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " Ges\\_Class & V2 & V3\\\\\n",
       "\\hline\n",
       "\t 6     & -2.12 & -2.12\\\\\n",
       "\t 5     &  0.67 &  0.67\\\\\n",
       "\t 5     & -0.19 & -0.19\\\\\n",
       "\t 3     &  0.37 &  0.37\\\\\n",
       "\t 4     & -0.40 & -0.40\\\\\n",
       "\t 8     & -1.08 & -1.08\\\\\n",
       "\t 7     &  1.26 &  1.26\\\\\n",
       "\t 4     & -0.33 & -0.33\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Ges_Class | V2 | V3 |\n",
       "|---|---|---|\n",
       "| 6     | -2.12 | -2.12 |\n",
       "| 5     |  0.67 |  0.67 |\n",
       "| 5     | -0.19 | -0.19 |\n",
       "| 3     |  0.37 |  0.37 |\n",
       "| 4     | -0.40 | -0.40 |\n",
       "| 8     | -1.08 | -1.08 |\n",
       "| 7     |  1.26 |  1.26 |\n",
       "| 4     | -0.33 | -0.33 |\n",
       "\n"
      ],
      "text/plain": [
       "  Ges_Class V2    V3   \n",
       "1 6         -2.12 -2.12\n",
       "2 5          0.67  0.67\n",
       "3 5         -0.19 -0.19\n",
       "4 3          0.37  0.37\n",
       "5 4         -0.40 -0.40\n",
       "6 8         -1.08 -1.08\n",
       "7 7          1.26  1.26\n",
       "8 4         -0.33 -0.33"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Ges_Class</th><th scope=col>V2</th><th scope=col>V3</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>6    </td><td>-1.53</td><td>-1.53</td></tr>\n",
       "\t<tr><td>5    </td><td> 1.79</td><td> 1.79</td></tr>\n",
       "\t<tr><td>5    </td><td> 0.52</td><td> 0.52</td></tr>\n",
       "\t<tr><td>3    </td><td> 0.31</td><td> 0.31</td></tr>\n",
       "\t<tr><td>4    </td><td>-0.47</td><td>-0.47</td></tr>\n",
       "\t<tr><td>8    </td><td> 0.66</td><td> 0.66</td></tr>\n",
       "\t<tr><td>7    </td><td> 1.24</td><td> 1.24</td></tr>\n",
       "\t<tr><td>4    </td><td>-1.30</td><td>-1.30</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " Ges\\_Class & V2 & V3\\\\\n",
       "\\hline\n",
       "\t 6     & -1.53 & -1.53\\\\\n",
       "\t 5     &  1.79 &  1.79\\\\\n",
       "\t 5     &  0.52 &  0.52\\\\\n",
       "\t 3     &  0.31 &  0.31\\\\\n",
       "\t 4     & -0.47 & -0.47\\\\\n",
       "\t 8     &  0.66 &  0.66\\\\\n",
       "\t 7     &  1.24 &  1.24\\\\\n",
       "\t 4     & -1.30 & -1.30\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Ges_Class | V2 | V3 |\n",
       "|---|---|---|\n",
       "| 6     | -1.53 | -1.53 |\n",
       "| 5     |  1.79 |  1.79 |\n",
       "| 5     |  0.52 |  0.52 |\n",
       "| 3     |  0.31 |  0.31 |\n",
       "| 4     | -0.47 | -0.47 |\n",
       "| 8     |  0.66 |  0.66 |\n",
       "| 7     |  1.24 |  1.24 |\n",
       "| 4     | -1.30 | -1.30 |\n",
       "\n"
      ],
      "text/plain": [
       "  Ges_Class V2    V3   \n",
       "1 6         -1.53 -1.53\n",
       "2 5          1.79  1.79\n",
       "3 5          0.52  0.52\n",
       "4 3          0.31  0.31\n",
       "5 4         -0.47 -0.47\n",
       "6 8          0.66  0.66\n",
       "7 7          1.24  1.24\n",
       "8 4         -1.30 -1.30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sample data\n",
    "\n",
    "x_acc[1:8,1:3]\n",
    "y_acc[1:8,1:3]\n",
    "z_acc[1:8,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e540c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate train set and test set\n",
    "\n",
    "cop_x_acc = x_acc\n",
    "cop_y_acc = y_acc[,-1]\n",
    "cop_z_acc = z_acc[,-1]\n",
    "\n",
    "test_cop_x_acc = test_x_acc\n",
    "test_cop_y_acc = test_y_acc[,-1]\n",
    "test_cop_z_acc = test_z_acc[,-1]\n",
    "\n",
    "#rename columns\n",
    "\n",
    "colnames(cop_x_acc)[2:316] <-paste(\"X.\", 1:315)\n",
    "colnames(cop_y_acc)[1:315] <-paste(\"Y.\", 1:315)\n",
    "colnames(cop_z_acc)[1:315] <-paste(\"Z.\", 1:315)\n",
    "\n",
    "colnames(test_cop_x_acc)[2:316] <-paste(\"X.\", 1:315)\n",
    "colnames(test_cop_y_acc)[1:315] <-paste(\"Y.\", 1:315)\n",
    "colnames(test_cop_z_acc)[1:315] <-paste(\"Z.\", 1:315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ffe952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine data\n",
    "train_Data_Conc <-as.data.frame(cbind(cop_x_acc[,],cop_y_acc[,],cop_z_acc[,]))\n",
    "test_Data_Conc <-as.data.frame(cbind(test_cop_x_acc[,],test_cop_y_acc[,],test_cop_z_acc[,]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86c55635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Ges_Class</th><th scope=col>X. 1</th><th scope=col>Y. 4</th><th scope=col>Z. 219</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>6    </td><td>-0.30</td><td>-2.12</td><td> 0.75</td></tr>\n",
       "\t<tr><td>5    </td><td> 1.63</td><td> 0.67</td><td>-0.69</td></tr>\n",
       "\t<tr><td>5    </td><td> 0.66</td><td>-0.19</td><td>-1.44</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " Ges\\_Class & X. 1 & Y. 4 & Z. 219\\\\\n",
       "\\hline\n",
       "\t 6     & -0.30 & -2.12 &  0.75\\\\\n",
       "\t 5     &  1.63 &  0.67 & -0.69\\\\\n",
       "\t 5     &  0.66 & -0.19 & -1.44\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Ges_Class | X. 1 | Y. 4 | Z. 219 |\n",
       "|---|---|---|---|\n",
       "| 6     | -0.30 | -2.12 |  0.75 |\n",
       "| 5     |  1.63 |  0.67 | -0.69 |\n",
       "| 5     |  0.66 | -0.19 | -1.44 |\n",
       "\n"
      ],
      "text/plain": [
       "  Ges_Class X. 1  Y. 4  Z. 219\n",
       "1 6         -0.30 -2.12  0.75 \n",
       "2 5          1.63  0.67 -0.69 \n",
       "3 5          0.66 -0.19 -1.44 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Ges_Class</th><th scope=col>X. 1</th><th scope=col>Y. 4</th><th scope=col>Z. 219</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>6    </td><td>-0.30</td><td>-2.12</td><td> 0.75</td></tr>\n",
       "\t<tr><td>5    </td><td> 1.63</td><td> 0.67</td><td>-0.69</td></tr>\n",
       "\t<tr><td>5    </td><td> 0.66</td><td>-0.19</td><td>-1.44</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " Ges\\_Class & X. 1 & Y. 4 & Z. 219\\\\\n",
       "\\hline\n",
       "\t 6     & -0.30 & -2.12 &  0.75\\\\\n",
       "\t 5     &  1.63 &  0.67 & -0.69\\\\\n",
       "\t 5     &  0.66 & -0.19 & -1.44\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Ges_Class | X. 1 | Y. 4 | Z. 219 |\n",
       "|---|---|---|---|\n",
       "| 6     | -0.30 | -2.12 |  0.75 |\n",
       "| 5     |  1.63 |  0.67 | -0.69 |\n",
       "| 5     |  0.66 | -0.19 | -1.44 |\n",
       "\n"
      ],
      "text/plain": [
       "  Ges_Class X. 1  Y. 4  Z. 219\n",
       "1 6         -0.30 -2.12  0.75 \n",
       "2 5          1.63  0.67 -0.69 \n",
       "3 5          0.66 -0.19 -1.44 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sample train\n",
    "train_Data_Conc[1:3, c(1,2,320,850)]\n",
    "train_Data_Conc[,1] = as.factor(train_Data_Conc[,1])\n",
    "train_Data_Conc[1:3, c(1,2,320,850)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be3d7fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Ges_Class</th><th scope=col>X. 1</th><th scope=col>Y. 4</th><th scope=col>Z. 219</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>5    </td><td> 1.56</td><td> 1.17</td><td>-1.16</td></tr>\n",
       "\t<tr><td>1    </td><td>-0.08</td><td>-1.11</td><td>-0.70</td></tr>\n",
       "\t<tr><td>4    </td><td> 1.51</td><td>-0.89</td><td> 0.50</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " Ges\\_Class & X. 1 & Y. 4 & Z. 219\\\\\n",
       "\\hline\n",
       "\t 5     &  1.56 &  1.17 & -1.16\\\\\n",
       "\t 1     & -0.08 & -1.11 & -0.70\\\\\n",
       "\t 4     &  1.51 & -0.89 &  0.50\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Ges_Class | X. 1 | Y. 4 | Z. 219 |\n",
       "|---|---|---|---|\n",
       "| 5     |  1.56 |  1.17 | -1.16 |\n",
       "| 1     | -0.08 | -1.11 | -0.70 |\n",
       "| 4     |  1.51 | -0.89 |  0.50 |\n",
       "\n"
      ],
      "text/plain": [
       "  Ges_Class X. 1  Y. 4  Z. 219\n",
       "1 5          1.56  1.17 -1.16 \n",
       "2 1         -0.08 -1.11 -0.70 \n",
       "3 4          1.51 -0.89  0.50 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Ges_Class</th><th scope=col>X. 1</th><th scope=col>Y. 4</th><th scope=col>Z. 219</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>5    </td><td> 1.56</td><td> 1.17</td><td>-1.16</td></tr>\n",
       "\t<tr><td>1    </td><td>-0.08</td><td>-1.11</td><td>-0.70</td></tr>\n",
       "\t<tr><td>4    </td><td> 1.51</td><td>-0.89</td><td> 0.50</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " Ges\\_Class & X. 1 & Y. 4 & Z. 219\\\\\n",
       "\\hline\n",
       "\t 5     &  1.56 &  1.17 & -1.16\\\\\n",
       "\t 1     & -0.08 & -1.11 & -0.70\\\\\n",
       "\t 4     &  1.51 & -0.89 &  0.50\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Ges_Class | X. 1 | Y. 4 | Z. 219 |\n",
       "|---|---|---|---|\n",
       "| 5     |  1.56 |  1.17 | -1.16 |\n",
       "| 1     | -0.08 | -1.11 | -0.70 |\n",
       "| 4     |  1.51 | -0.89 |  0.50 |\n",
       "\n"
      ],
      "text/plain": [
       "  Ges_Class X. 1  Y. 4  Z. 219\n",
       "1 5          1.56  1.17 -1.16 \n",
       "2 1         -0.08 -1.11 -0.70 \n",
       "3 4          1.51 -0.89  0.50 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sample test\n",
    "test_Data_Conc[1:3, c(1,2,320,850)]\n",
    "test_Data_Conc[,1] = as.factor (test_Data_Conc[,1])\n",
    "test_Data_Conc[1:3, c(1,2,320,850)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "420cb555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>896</li>\n",
       "\t<li>946</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 896\n",
       "\\item 946\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 896\n",
       "2. 946\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 896 946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>3582</li>\n",
       "\t<li>946</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3582\n",
       "\\item 946\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3582\n",
       "2. 946\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 3582  946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show dimension\n",
    "dim(train_Data_Conc)\n",
    "dim(test_Data_Conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef94efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale\n",
    "#doing something distance based then scaled data should be used\n",
    "Scaled_Train_Data_Conc <- train_Data_Conc\n",
    "Scaled_Train_Data_Conc[,-1] <- scale(train_Data_Conc[,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd229055",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaled_Test_Data_Conc <- test_Data_Conc\n",
    "Scaled_Test_Data_Conc[,-1] <- scale(test_Data_Conc[,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55a693a",
   "metadata": {},
   "source": [
    "In the first column we have the class ID, the stadandardized x1-x2---y1-y2--z1-z2-- in the rest of the columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde584df",
   "metadata": {},
   "source": [
    "### 1a)Suppose we decided to apply a nearest-neighbor (NN) classifier to find the labels of test instances. You can use the strategy you employed when you apply PCA to this data in Homework 2 (i.e. concatenation of the axes). Propose two distance measures for computing similarity between two time series. The distance calculation on the concatenated time series implicitly weights the distances of each axis in an equal way. For each distance measure alternative, use the training data to identify the ideal value of k which minimizes the error of a10-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de27f5b",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "720bb31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train with 10 fold cross - validation\n",
    "\n",
    "trControl <- caret:::trainControl(method  = \"cv\", number  = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff30f52",
   "metadata": {},
   "source": [
    "Training the models from now on.\n",
    "\n",
    "Kernel is selected as \"rectangular\" (which is standard unweighted knn)\n",
    "\n",
    "Trying k: 1 to 5\n",
    "\n",
    "Try distance euclidean  (minkowski parameter = 2)\n",
    "\n",
    "Try distance manhattan  (minkowski parameter = 1)\n",
    "\n",
    "Using the Manhattan metric, a distance between two time series is the ~ area between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e761d6",
   "metadata": {},
   "source": [
    "#### For Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ff6a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1 <- caret:::train(Ges_Class ~ .,\n",
    "             method     = \"kknn\",\n",
    "             tuneGrid   = expand.grid(kmax = 1:5, distance = 1 , kernel= \"rectangular\"),\n",
    "             trControl  = trControl,\n",
    "             metric     = \"Accuracy\",\n",
    "             data       = Scaled_Train_Data_Conc)\n",
    "\n",
    "#trconrol -> 10 fold cv is done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12c8ff9",
   "metadata": {},
   "source": [
    "The results are below for Manhattan distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2826380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k-Nearest Neighbors \n",
    "\n",
    "896 samples\n",
    "945 predictors\n",
    "  8 classes: '1', '2', '3', '4', '5', '6', '7', '8' \n",
    "\n",
    "No pre-processing\n",
    "Resampling: Cross-Validated (10 fold) \n",
    "Summary of sample sizes: 805, 806, 806, 805, 808, 805, ... \n",
    "Resampling results across tuning parameters:\n",
    "\n",
    "  kmax  Accuracy   Kappa    \n",
    "  1     0.9576593  0.9515512\n",
    "  2     0.9576593  0.9515512\n",
    "  3     0.9587829  0.9528373\n",
    "  4     0.9587829  0.9528373\n",
    "  5     0.9587829  0.9528373\n",
    "\n",
    "Tuning parameter 'distance' was held constant at a value of 1\n",
    "Tuning parameter 'kernel' was held constant at a value of rectangular\n",
    "Accuracy was used to select the optimal model using the largest value.\n",
    "The final values used for the model were kmax = 5, distance = 1 and kernel = rectangular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fba52b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Best K=3, when dist=1, Manhattan\n",
    "\n",
    "When distance was manhattan, the k value is selected as 3. Although it is given as 5 above output (last line), overcomplicating the model was the same level of accuracy is not reasonable. Over 95 % accuracy is noted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6cfab9",
   "metadata": {},
   "source": [
    "#### For Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58e5a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2 <- train(Ges_Class ~ .,\n",
    "              method     = \"kknn\",\n",
    "              tuneGrid   = expand.grid(kmax = 1:5, distance = 2 , kernel= \"rectangular\"),\n",
    "              trControl  = trControl,\n",
    "              metric     = \"Accuracy\",\n",
    "              data       = Scaled_Train_Data_Conc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab67c5",
   "metadata": {},
   "source": [
    "The results are below for Euclidean distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86a0865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k-Nearest Neighbors \n",
    "\n",
    "896 samples\n",
    "945 predictors\n",
    "  8 classes: '1', '2', '3', '4', '5', '6', '7', '8' \n",
    "\n",
    "No pre-processing\n",
    "Resampling: Cross-Validated (10 fold) \n",
    "Summary of sample sizes: 807, 807, 807, 806, 804, 805, ... \n",
    "Resampling results across tuning parameters:\n",
    "\n",
    "  kmax  Accuracy   Kappa    \n",
    "  1     0.9497179  0.9424687\n",
    "  2     0.9497179  0.9424687\n",
    "  3     0.9442490  0.9361971\n",
    "  4     0.9442490  0.9361971\n",
    "  5     0.9442490  0.9361971\n",
    "\n",
    "Tuning parameter 'distance' was held constant at a value of 2\n",
    "Tuning parameter 'kernel' was held constant at a value of rectangular\n",
    "Accuracy was used to select the optimal model using the largest value.\n",
    "The final values used for the model were kmax = 2, distance = 2 and kernel = rectangular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5766d263",
   "metadata": {},
   "source": [
    "When distance was euclidean, the k value is selected as 2, as suggested by the output. Almost 95% acurracy is noted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e40d6b7",
   "metadata": {},
   "source": [
    "### 1b) Using the value of k (identified for each distance measure) in part (a) and evaluate your final performance on the test data and present your results in a (8-by-8) confusion matrix, showing the counts for actual and predicted labels. In addition, quote the runtime and accuracy for your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66467a25",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2adba3b",
   "metadata": {},
   "source": [
    "#### For Manhattan distance, with K = 3, train on the training data and test it on the test data. The confusion matrix printed out.  The misclassification error and the accuracy is also printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54fb3c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "      1   2   3   4   5   6   7   8\n",
       "  1 432   0   0   2   0   3   0   0\n",
       "  2   1 451   0   0   0   0   0   0\n",
       "  3   2   0 415   0  12  20   5   0\n",
       "  4   3   0   0 384  48   8   0   7\n",
       "  5   3   0   4   2 422   2   0   0\n",
       "  6   6   0   4  12  27 400   0   0\n",
       "  7   1   0   2   0   0   0 444   0\n",
       "  8   0   0   0   1   1   0   0 458"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0491345616973757"
      ],
      "text/latex": [
       "0.0491345616973757"
      ],
      "text/markdown": [
       "0.0491345616973757"
      ],
      "text/plain": [
       "[1] 0.04913456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.950865438302624"
      ],
      "text/latex": [
       "0.950865438302624"
      ],
      "text/markdown": [
       "0.950865438302624"
      ],
      "text/plain": [
       "[1] 0.9508654"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 26.51121 secs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(\"kknn\")\n",
    "####manhattan\n",
    "start.time <- Sys.time()\n",
    "\n",
    "Gesture.kknn1 <- kknn(Ges_Class ~ ., Scaled_Train_Data_Conc, Scaled_Test_Data_Conc,distance = 1, k=3, kernel =\"rectangular\")\n",
    "\n",
    "table(Scaled_Test_Data_Conc$Ges_Class, Gesture.kknn1$fit)\n",
    "\n",
    "error_man = 1 - sum (Scaled_Test_Data_Conc$Ges_Class ==  Gesture.kknn1$fit)/nrow(Scaled_Test_Data_Conc)\n",
    "error_man\n",
    "acc_man= 1- error_man\n",
    "acc_man\n",
    "end.time <- Sys.time()\n",
    "time.taken <- end.time - start.time\n",
    "time.taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d93ad6",
   "metadata": {},
   "source": [
    "To interpret the confusion matrix:\n",
    "\n",
    "For instance 432 of the class1 test instances were classified correctly,\n",
    "whereas 2 of those were misclassified as class4 and 3 of them are misclassified as class6.\n",
    "\n",
    "The accuracy is over 95 %.\n",
    "\n",
    "Less than 5 % misclassification is observed.\n",
    "\n",
    "It took less then 30 seconds to obtain the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ab1efa",
   "metadata": {},
   "source": [
    "#### For Euclidean distance, with K = 2, train on the training data and test it on the test data. The confusion matrix printed out. The misclassification error and the accuracy is also printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0442865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "      1   2   3   4   5   6   7   8\n",
       "  1 429   0   0   2   0   5   1   0\n",
       "  2   1 450   0   0   0   0   1   0\n",
       "  3   2   0 416   1  14  15   6   0\n",
       "  4   6   0   0 380  51  10   0   3\n",
       "  5   2   0   9   3 416   3   0   0\n",
       "  6   7   0   3  12  19 407   1   0\n",
       "  7   0   0   3   0   0   0 444   0\n",
       "  8   0   0   0   4   2   0   0 454"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.051926298157454"
      ],
      "text/latex": [
       "0.051926298157454"
      ],
      "text/markdown": [
       "0.051926298157454"
      ],
      "text/plain": [
       "[1] 0.0519263"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.948073701842546"
      ],
      "text/latex": [
       "0.948073701842546"
      ],
      "text/markdown": [
       "0.948073701842546"
      ],
      "text/plain": [
       "[1] 0.9480737"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 4.274762 secs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####euclidean\n",
    "start.time <- Sys.time()\n",
    "\n",
    "Gesture.kknn2 <- kknn(Ges_Class ~ ., Scaled_Train_Data_Conc, Scaled_Test_Data_Conc,distance = 2, k=2, kernel =\"rectangular\")\n",
    "\n",
    "table(Scaled_Test_Data_Conc$Ges_Class, Gesture.kknn2$fit)\n",
    "\n",
    "error_euc = 1 - sum (Scaled_Test_Data_Conc$Ges_Class ==  Gesture.kknn2$fit)/nrow(Scaled_Test_Data_Conc)\n",
    "error_euc\n",
    "end.time <- Sys.time()\n",
    "\n",
    "acc_euc= 1- error_euc\n",
    "acc_euc\n",
    "\n",
    "time.taken <- end.time - start.time\n",
    "time.taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68686a86",
   "metadata": {},
   "source": [
    "To interpret the confusion matrix:\n",
    "\n",
    "For instance 450 of the class2 test instances were classified correctly, whereas 1 of them was misclassified as class1 and 1 of them are misclassified as class7.\n",
    "\n",
    "The accuracy is about 95 %.\n",
    "\n",
    "About 5 % misclassification is observed.\n",
    "\n",
    "It took about 4 seconds to obtain the results, it was much faster then the first model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b03a98d",
   "metadata": {},
   "source": [
    "#### These parts below are just for re-checking the steps done so far. The same process was performed in a different manner. Further, if we were to compare Manhattan distance with 5 different k values vs Euclidean distance with 5 different k values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e471774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###overall\n",
    "fit <- train(Ges_Class ~ .,\n",
    "             method     = \"kknn\",\n",
    "             tuneGrid   = expand.grid(kmax = 1:5, distance = 1:2 , kernel= \"rectangular\"),\n",
    "             trControl  = trControl,\n",
    "             metric     = \"Accuracy\",\n",
    "             data       = Scaled_Train_Data_Conc)\n",
    "\n",
    "###overall end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d80b1e",
   "metadata": {},
   "source": [
    "The below result were obtained comparing  5 different levels of k across 2 different distance measures (dist = 1 Manhattan and dist = 2, Euclidean).\n",
    "\n",
    "The results suggest k = 5 and distance = 1 with the highest accuracy, however it is clear that we can get the same level of accuracy with  k=3 with distance = 1, which was implemented above. And, we got a little bit higher accuracy with this model (manhattan, K =3), than the other (Euclidean K =2) which confirms our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "444f6379",
   "metadata": {},
   "outputs": [],
   "source": [
    "k-Nearest Neighbors \n",
    "\n",
    "896 samples\n",
    "945 predictors\n",
    "  8 classes: '1', '2', '3', '4', '5', '6', '7', '8' \n",
    "\n",
    "No pre-processing\n",
    "Resampling: Cross-Validated (10 fold) \n",
    "Summary of sample sizes: 805, 807, 806, 806, 806, 807, ... \n",
    "Resampling results across tuning parameters:\n",
    "\n",
    "  kmax  distance  Accuracy   Kappa    \n",
    "  1     1         0.9586736  0.9527245\n",
    "  1     2         0.9398066  0.9311277\n",
    "  2     1         0.9586736  0.9527245\n",
    "  2     2         0.9398066  0.9311277\n",
    "  3     1         0.9586736  0.9527245\n",
    "  3     2         0.9442019  0.9361512\n",
    "  4     1         0.9586736  0.9527245\n",
    "  4     2         0.9419545  0.9335789\n",
    "  5     1         0.9586736  0.9527245\n",
    "  5     2         0.9419545  0.9335789\n",
    "\n",
    "Tuning parameter 'kernel' was held constant at a value of rectangular\n",
    "Accuracy was used to select the optimal model using the largest value.\n",
    "The final values used for the model were kmax = 5, distance = 1 and kernel = rectangular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77e178b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "train.kknn(formula = Ges_Class ~ ., data = Scaled_Train_Data_Conc,     kmax = 5, distance = 1, kernel = \"rectangular\")\n",
       "\n",
       "Type of response variable: nominal\n",
       "Minimal misclassification: 0.0390625\n",
       "Best kernel: rectangular\n",
       "Best k: 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   \n",
       "      1   2   3   4   5   6   7   8\n",
       "  1 433   1   2   4   3   6   0   0\n",
       "  2   0 451   0   0   0   0   0   0\n",
       "  3   0   0 415   0   9   5   3   0\n",
       "  4   1   0   0 396   4  11   0   3\n",
       "  5   0   0  16  39 414  17   0   1\n",
       "  6   3   0  16   8   3 410   0   0\n",
       "  7   0   0   5   0   0   0 444   0\n",
       "  8   0   0   0   3   0   0   0 456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####try in another way,with a different fucntion.It has the same results in terms of misclassification error (~accuracy)\n",
    "#we get similar accuracy\n",
    "#train with possible K = 1:5 values in manhattan distance\n",
    "#test on test data\n",
    "#print confusion matrix \n",
    "(fit.train1 <- train.kknn(Ges_Class ~ ., Scaled_Train_Data_Conc, kmax = 5, distance = 1, kernel =\"rectangular\"))\n",
    "\n",
    "table(predict(fit.train1, Scaled_Test_Data_Conc), Scaled_Test_Data_Conc$Ges_Class)\n",
    "###\n",
    "#we get similar accuracy for K=1 and K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14d4ffcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "train.kknn(formula = Ges_Class ~ ., data = Scaled_Train_Data_Conc,     kmax = 5, distance = 2, kernel = \"rectangular\")\n",
       "\n",
       "Type of response variable: nominal\n",
       "Minimal misclassification: 0.05245536\n",
       "Best kernel: rectangular\n",
       "Best k: 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   \n",
       "      1   2   3   4   5   6   7   8\n",
       "  1 429   1   1   5   3   5   0   0\n",
       "  2   0 449   0   0   0   0   0   0\n",
       "  3   0   0 414   0   5   5   2   0\n",
       "  4   3   0   0 372   1  14   0   1\n",
       "  5   0   0  14  59 422  29   0   1\n",
       "  6   4   0  21   8   2 395   0   0\n",
       "  7   1   2   4   0   0   1 445   0\n",
       "  8   0   0   0   6   0   0   0 458"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####try in another way,with a different fucntion. It has the same results in terms of misclassification error (~accuracy)\n",
    "\n",
    "#train with possible K = 1:5 values in eucl. distance\n",
    "#test on test data\n",
    "#print confusion matrix \n",
    "\n",
    "(fit.train2 <- train.kknn(Ges_Class ~ ., Scaled_Train_Data_Conc, kmax = 5, distance = 2,kernel =\"rectangular\"))\n",
    "\n",
    "table(predict(fit.train2, Scaled_Test_Data_Conc), Scaled_Test_Data_Conc$Ges_Class)\n",
    "\n",
    "#we get similar accuracy for K=2 and K = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a76542",
   "metadata": {},
   "source": [
    "#### Overall results:\n",
    "For Manhattan distance, with K = 3\n",
    "\n",
    "The accuracy is over 95 %.\n",
    "Less than 5 % misclassification is observed.\n",
    "It took less than 30 seconds to obtain the results.\n",
    "\n",
    "For Euclidean distance, with K = 2\n",
    "\n",
    "About 5 % misclassification is observed.\n",
    "It took about 4 seconds to obtain the results, it was much faster then the first model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e171d0c2",
   "metadata": {},
   "source": [
    "### 1c)The observations from different axes are weighted equally if we compute the distance over each axis and sum them to obtain a final similarity measure. Is this reasonable? For example, we can ompute the distance as below:(w.distx+w*disty+w*distz) where DistX is the distance based on the acceleration only on X axis, DistY is for Y axis and so on. Do you think weighting the distances over different axes to obtain a final similarity measure makes sense for classification? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4cb894",
   "metadata": {},
   "source": [
    "Yes, weighting some distances more than the others make sense in this setting.\n",
    "We may interpret this kind of unequal weights as eliminating the noise in the z-axis.\n",
    "Since the actual data could be presented in a 2D figure schematically, we may infer that the z axis do not provide as much as the x and y axes (assuming the motion takes place mostly on xy plane). A similarity heavily based on these two axes may be a more accurate metric compared to computing a distance where the observations from different axes are weighted equally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb57e61e",
   "metadata": {},
   "source": [
    "## Task 2 – Linear models on alternative representations of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af30ac",
   "metadata": {},
   "source": [
    "### 2a) Train a logistic regression model on the training data and use the model to make a prediction on the test data. Note that you will obtain probabilistic predictions (i.e. probability of a time series being from Class 3 if you encoded Class 3 as 1 in binary classification setting). This will require you to select a threshold since 0.5 as a threshold may not work well under this imbalanced class setting. To make things easier, use the ratio of Class 3 instances in the training data as threshold. Use the learned model to predict the class for test data. Present your results in a (2-by-2) confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ed439d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Ges_Class</th><th scope=col>X. 1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>6          </td><td>-0.42019517</td></tr>\n",
       "\t<tr><td>5          </td><td> 1.78273070</td></tr>\n",
       "\t<tr><td>5          </td><td> 0.67556070</td></tr>\n",
       "\t<tr><td>3          </td><td>-0.06635733</td></tr>\n",
       "\t<tr><td>4          </td><td> 1.39465049</td></tr>\n",
       "\t<tr><td>8          </td><td>-0.62564939</td></tr>\n",
       "\t<tr><td>7          </td><td> 1.60010472</td></tr>\n",
       "\t<tr><td>4          </td><td> 0.27606638</td></tr>\n",
       "\t<tr><td>4          </td><td> 1.04081266</td></tr>\n",
       "\t<tr><td>6          </td><td>-1.42463805</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " Ges\\_Class & X. 1\\\\\n",
       "\\hline\n",
       "\t 6           & -0.42019517\\\\\n",
       "\t 5           &  1.78273070\\\\\n",
       "\t 5           &  0.67556070\\\\\n",
       "\t 3           & -0.06635733\\\\\n",
       "\t 4           &  1.39465049\\\\\n",
       "\t 8           & -0.62564939\\\\\n",
       "\t 7           &  1.60010472\\\\\n",
       "\t 4           &  0.27606638\\\\\n",
       "\t 4           &  1.04081266\\\\\n",
       "\t 6           & -1.42463805\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Ges_Class | X. 1 |\n",
       "|---|---|\n",
       "| 6           | -0.42019517 |\n",
       "| 5           |  1.78273070 |\n",
       "| 5           |  0.67556070 |\n",
       "| 3           | -0.06635733 |\n",
       "| 4           |  1.39465049 |\n",
       "| 8           | -0.62564939 |\n",
       "| 7           |  1.60010472 |\n",
       "| 4           |  0.27606638 |\n",
       "| 4           |  1.04081266 |\n",
       "| 6           | -1.42463805 |\n",
       "\n"
      ],
      "text/plain": [
       "   Ges_Class X. 1       \n",
       "1  6         -0.42019517\n",
       "2  5          1.78273070\n",
       "3  5          0.67556070\n",
       "4  3         -0.06635733\n",
       "5  4          1.39465049\n",
       "6  8         -0.62564939\n",
       "7  7          1.60010472\n",
       "8  4          0.27606638\n",
       "9  4          1.04081266\n",
       "10 6         -1.42463805"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Ges_Class</th><th scope=col>X. 1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0          </td><td>-0.42019517</td></tr>\n",
       "\t<tr><td>0          </td><td> 1.78273070</td></tr>\n",
       "\t<tr><td>0          </td><td> 0.67556070</td></tr>\n",
       "\t<tr><td>1          </td><td>-0.06635733</td></tr>\n",
       "\t<tr><td>0          </td><td> 1.39465049</td></tr>\n",
       "\t<tr><td>0          </td><td>-0.62564939</td></tr>\n",
       "\t<tr><td>0          </td><td> 1.60010472</td></tr>\n",
       "\t<tr><td>0          </td><td> 0.27606638</td></tr>\n",
       "\t<tr><td>0          </td><td> 1.04081266</td></tr>\n",
       "\t<tr><td>0          </td><td>-1.42463805</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " Ges\\_Class & X. 1\\\\\n",
       "\\hline\n",
       "\t 0           & -0.42019517\\\\\n",
       "\t 0           &  1.78273070\\\\\n",
       "\t 0           &  0.67556070\\\\\n",
       "\t 1           & -0.06635733\\\\\n",
       "\t 0           &  1.39465049\\\\\n",
       "\t 0           & -0.62564939\\\\\n",
       "\t 0           &  1.60010472\\\\\n",
       "\t 0           &  0.27606638\\\\\n",
       "\t 0           &  1.04081266\\\\\n",
       "\t 0           & -1.42463805\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Ges_Class | X. 1 |\n",
       "|---|---|\n",
       "| 0           | -0.42019517 |\n",
       "| 0           |  1.78273070 |\n",
       "| 0           |  0.67556070 |\n",
       "| 1           | -0.06635733 |\n",
       "| 0           |  1.39465049 |\n",
       "| 0           | -0.62564939 |\n",
       "| 0           |  1.60010472 |\n",
       "| 0           |  0.27606638 |\n",
       "| 0           |  1.04081266 |\n",
       "| 0           | -1.42463805 |\n",
       "\n"
      ],
      "text/plain": [
       "   Ges_Class X. 1       \n",
       "1  0         -0.42019517\n",
       "2  0          1.78273070\n",
       "3  0          0.67556070\n",
       "4  1         -0.06635733\n",
       "5  0          1.39465049\n",
       "6  0         -0.62564939\n",
       "7  0          1.60010472\n",
       "8  0          0.27606638\n",
       "9  0          1.04081266\n",
       "10 0         -1.42463805"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Ges_Class</th><th scope=col>X. 1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>10</th><td>1           </td><td>-0.074001045</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>2           </td><td>-0.918031281</td></tr>\n",
       "\t<tr><th scope=row>12</th><td>4           </td><td> 0.145678058</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>3           </td><td> 0.006933361</td></tr>\n",
       "\t<tr><th scope=row>14</th><td>4           </td><td> 0.596598321</td></tr>\n",
       "\t<tr><th scope=row>15</th><td>4           </td><td> 1.879986763</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>1           </td><td>-1.738937402</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>5           </td><td> 0.099429826</td></tr>\n",
       "\t<tr><th scope=row>18</th><td>6           </td><td>-1.623316822</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>4           </td><td> 0.319108928</td></tr>\n",
       "\t<tr><th scope=row>20</th><td>3           </td><td>-1.738937402</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & Ges\\_Class & X. 1\\\\\n",
       "\\hline\n",
       "\t10 & 1            & -0.074001045\\\\\n",
       "\t11 & 2            & -0.918031281\\\\\n",
       "\t12 & 4            &  0.145678058\\\\\n",
       "\t13 & 3            &  0.006933361\\\\\n",
       "\t14 & 4            &  0.596598321\\\\\n",
       "\t15 & 4            &  1.879986763\\\\\n",
       "\t16 & 1            & -1.738937402\\\\\n",
       "\t17 & 5            &  0.099429826\\\\\n",
       "\t18 & 6            & -1.623316822\\\\\n",
       "\t19 & 4            &  0.319108928\\\\\n",
       "\t20 & 3            & -1.738937402\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Ges_Class | X. 1 |\n",
       "|---|---|---|\n",
       "| 10 | 1            | -0.074001045 |\n",
       "| 11 | 2            | -0.918031281 |\n",
       "| 12 | 4            |  0.145678058 |\n",
       "| 13 | 3            |  0.006933361 |\n",
       "| 14 | 4            |  0.596598321 |\n",
       "| 15 | 4            |  1.879986763 |\n",
       "| 16 | 1            | -1.738937402 |\n",
       "| 17 | 5            |  0.099429826 |\n",
       "| 18 | 6            | -1.623316822 |\n",
       "| 19 | 4            |  0.319108928 |\n",
       "| 20 | 3            | -1.738937402 |\n",
       "\n"
      ],
      "text/plain": [
       "   Ges_Class X. 1        \n",
       "10 1         -0.074001045\n",
       "11 2         -0.918031281\n",
       "12 4          0.145678058\n",
       "13 3          0.006933361\n",
       "14 4          0.596598321\n",
       "15 4          1.879986763\n",
       "16 1         -1.738937402\n",
       "17 5          0.099429826\n",
       "18 6         -1.623316822\n",
       "19 4          0.319108928\n",
       "20 3         -1.738937402"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Ges_Class</th><th scope=col>X. 1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>10</th><td>0           </td><td>-0.074001045</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>0           </td><td>-0.918031281</td></tr>\n",
       "\t<tr><th scope=row>12</th><td>0           </td><td> 0.145678058</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>1           </td><td> 0.006933361</td></tr>\n",
       "\t<tr><th scope=row>14</th><td>0           </td><td> 0.596598321</td></tr>\n",
       "\t<tr><th scope=row>15</th><td>0           </td><td> 1.879986763</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>0           </td><td>-1.738937402</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>0           </td><td> 0.099429826</td></tr>\n",
       "\t<tr><th scope=row>18</th><td>0           </td><td>-1.623316822</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>0           </td><td> 0.319108928</td></tr>\n",
       "\t<tr><th scope=row>20</th><td>1           </td><td>-1.738937402</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & Ges\\_Class & X. 1\\\\\n",
       "\\hline\n",
       "\t10 & 0            & -0.074001045\\\\\n",
       "\t11 & 0            & -0.918031281\\\\\n",
       "\t12 & 0            &  0.145678058\\\\\n",
       "\t13 & 1            &  0.006933361\\\\\n",
       "\t14 & 0            &  0.596598321\\\\\n",
       "\t15 & 0            &  1.879986763\\\\\n",
       "\t16 & 0            & -1.738937402\\\\\n",
       "\t17 & 0            &  0.099429826\\\\\n",
       "\t18 & 0            & -1.623316822\\\\\n",
       "\t19 & 0            &  0.319108928\\\\\n",
       "\t20 & 1            & -1.738937402\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Ges_Class | X. 1 |\n",
       "|---|---|---|\n",
       "| 10 | 0            | -0.074001045 |\n",
       "| 11 | 0            | -0.918031281 |\n",
       "| 12 | 0            |  0.145678058 |\n",
       "| 13 | 1            |  0.006933361 |\n",
       "| 14 | 0            |  0.596598321 |\n",
       "| 15 | 0            |  1.879986763 |\n",
       "| 16 | 0            | -1.738937402 |\n",
       "| 17 | 0            |  0.099429826 |\n",
       "| 18 | 0            | -1.623316822 |\n",
       "| 19 | 0            |  0.319108928 |\n",
       "| 20 | 1            | -1.738937402 |\n",
       "\n"
      ],
      "text/plain": [
       "   Ges_Class X. 1        \n",
       "10 0         -0.074001045\n",
       "11 0         -0.918031281\n",
       "12 0          0.145678058\n",
       "13 1          0.006933361\n",
       "14 0          0.596598321\n",
       "15 0          1.879986763\n",
       "16 0         -1.738937402\n",
       "17 0          0.099429826\n",
       "18 0         -1.623316822\n",
       "19 0          0.319108928\n",
       "20 1         -1.738937402"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#install.packages(\"glmnet\")\n",
    "library(\"glmnet\")\n",
    "\n",
    "#make the class info binary\n",
    "#put 1 if class3 else put 0\n",
    "#transform both training and test data\n",
    "\n",
    "#training\n",
    "c_train=Scaled_Train_Data_Conc\n",
    "c_train[1:10,1:2] #now we have 1,2,3,4,5,6\n",
    "\n",
    "c_train$Ges_Class=ifelse(c_train$Ges_Class==3,1,0)\n",
    "c_train[1:10,1:2] #now we have 0-1\n",
    "\n",
    "#for test set\n",
    "c_test=Scaled_Test_Data_Conc\n",
    "c_test[10:20,1:2]\n",
    "c_test$Ges_Class=ifelse(c_test$Ges_Class==3,1,0)\n",
    "c_test[10:20,1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8268f5",
   "metadata": {},
   "source": [
    "#### Perform logistic regression. Create the model using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a37949f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"glm.fit: algorithm did not converge\""
     ]
    }
   ],
   "source": [
    "##logistic regression\n",
    "\n",
    "log_reg=glm(Ges_Class~.,c_train,family='binomial')\n",
    "#summary(log_reg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cf0c7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>-26.5660685322671</dd>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>-26.5660685260373</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>-26.5660685240637</dd>\n",
       "\t<dt>4</dt>\n",
       "\t\t<dd>26.5660638737218</dd>\n",
       "\t<dt>5</dt>\n",
       "\t\t<dd>-26.5660685213725</dd>\n",
       "\t<dt>6</dt>\n",
       "\t\t<dd>-26.5660685206876</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[1] -26.5660685322671\n",
       "\\item[2] -26.5660685260373\n",
       "\\item[3] -26.5660685240637\n",
       "\\item[4] 26.5660638737218\n",
       "\\item[5] -26.5660685213725\n",
       "\\item[6] -26.5660685206876\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "1\n",
       ":   -26.56606853226712\n",
       ":   -26.56606852603733\n",
       ":   -26.56606852406374\n",
       ":   26.56606387372185\n",
       ":   -26.56606852137256\n",
       ":   -26.5660685206876\n",
       "\n"
      ],
      "text/plain": [
       "        1         2         3         4         5         6 \n",
       "-26.56607 -26.56607 -26.56607  26.56606 -26.56607 -26.56607 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted=predict(log_reg,c_train)\n",
    "head(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb490d15",
   "metadata": {},
   "source": [
    "This warning checks if the rank of the data matrix is at least equal to the number of parameters/features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "594af4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>2.90070144014886e-12</dd>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>2.90070145821968e-12</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>2.90070146394452e-12</dd>\n",
       "\t<dt>4</dt>\n",
       "\t\t<dd>0.999999999997099</dd>\n",
       "\t<dt>5</dt>\n",
       "\t\t<dd>2.90070147175087e-12</dd>\n",
       "\t<dt>6</dt>\n",
       "\t\t<dd>2.90070147373741e-12</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[1] 2.90070144014886e-12\n",
       "\\item[2] 2.90070145821968e-12\n",
       "\\item[3] 2.90070146394452e-12\n",
       "\\item[4] 0.999999999997099\n",
       "\\item[5] 2.90070147175087e-12\n",
       "\\item[6] 2.90070147373741e-12\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "1\n",
       ":   2.90070144014886e-122\n",
       ":   2.90070145821968e-123\n",
       ":   2.90070146394452e-124\n",
       ":   0.9999999999970995\n",
       ":   2.90070147175087e-126\n",
       ":   2.90070147373741e-12\n",
       "\n"
      ],
      "text/plain": [
       "           1            2            3            4            5            6 \n",
       "2.900701e-12 2.900701e-12 2.900701e-12 1.000000e+00 2.900701e-12 2.900701e-12 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted=predict(log_reg,c_train,type='response')\n",
    "head(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03054703",
   "metadata": {},
   "source": [
    "The above are the probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51e8c55",
   "metadata": {},
   "source": [
    "#### Check the model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46a56692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>0</th><th scope=col>1</th><th scope=col>Sum</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>0</th><td>790</td><td>  0</td><td>790</td></tr>\n",
       "\t<tr><th scope=row>1</th><td>  0</td><td>106</td><td>106</td></tr>\n",
       "\t<tr><th scope=row>Sum</th><td>790</td><td>106</td><td>896</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & 0 & 1 & Sum\\\\\n",
       "\\hline\n",
       "\t0 & 790 &   0 & 790\\\\\n",
       "\t1 &   0 & 106 & 106\\\\\n",
       "\tSum & 790 & 106 & 896\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 0 | 1 | Sum |\n",
       "|---|---|---|---|\n",
       "| 0 | 790 |   0 | 790 |\n",
       "| 1 |   0 | 106 | 106 |\n",
       "| Sum | 790 | 106 | 896 |\n",
       "\n"
      ],
      "text/plain": [
       "     prediction\n",
       "      0   1   Sum\n",
       "  0   790   0 790\n",
       "  1     0 106 106\n",
       "  Sum 790 106 896"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check training data\n",
    "predicted_prob <-  predict(log_reg,c_train,type='response')\n",
    "##ratio calculation\n",
    "ratio= sum(c_train[,1])/ length(c_train[,1])\n",
    "\n",
    "prediction <- as.integer(predicted_prob > ratio)\n",
    "\n",
    "confusion_mat <- addmargins(table(c_train$Ges_Class, prediction))\n",
    "\n",
    "confusion_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f2e48e",
   "metadata": {},
   "source": [
    "It gets all correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be665713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training accuracy\n",
    "trainerr =  1- (sum(diag((confusion_mat[1:2,1:2]))) /  confusion_mat[3,3])\n",
    "trainerr\n",
    "\n",
    "acc_train= 1- trainerr\n",
    "acc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690d7f2e",
   "metadata": {},
   "source": [
    "Error is 0. Accuracy is 1.  Overfitting is suspectible. It probably picks up many variables to build a \"good\" model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aff8b5",
   "metadata": {},
   "source": [
    "#### Check on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ff10b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 0.13376 secs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>0</th><th scope=col>1</th><th scope=col>Sum</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>0</th><td>1586</td><td>1542</td><td>3128</td></tr>\n",
       "\t<tr><th scope=row>1</th><td> 249</td><td> 205</td><td> 454</td></tr>\n",
       "\t<tr><th scope=row>Sum</th><td>1835</td><td>1747</td><td>3582</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & 0 & 1 & Sum\\\\\n",
       "\\hline\n",
       "\t0 & 1586 & 1542 & 3128\\\\\n",
       "\t1 &  249 &  205 &  454\\\\\n",
       "\tSum & 1835 & 1747 & 3582\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 0 | 1 | Sum |\n",
       "|---|---|---|---|\n",
       "| 0 | 1586 | 1542 | 3128 |\n",
       "| 1 |  249 |  205 |  454 |\n",
       "| Sum | 1835 | 1747 | 3582 |\n",
       "\n"
      ],
      "text/plain": [
       "     prediction_test\n",
       "      0    1    Sum \n",
       "  0   1586 1542 3128\n",
       "  1    249  205  454\n",
       "  Sum 1835 1747 3582"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#on test data\n",
    "start.time <- Sys.time()\n",
    "\n",
    "predicted_prob_test <-  predict(log_reg,c_test,type='response')\n",
    "#predicted_prob_test\n",
    "prediction_test <- as.integer(predicted_prob_test > ratio)\n",
    "\n",
    "end.time <- Sys.time()\n",
    "time.taken <- end.time - start.time\n",
    "time.taken\n",
    "\n",
    "confusion_mat_test <- addmargins(table(c_test$Ges_Class, prediction_test))\n",
    "\n",
    "confusion_mat_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd317e2",
   "metadata": {},
   "source": [
    "About half of the class#3 classification was done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea2afaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.5"
      ],
      "text/latex": [
       "0.5"
      ],
      "text/markdown": [
       "0.5"
      ],
      "text/plain": [
       "[1] 0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.5"
      ],
      "text/latex": [
       "0.5"
      ],
      "text/markdown": [
       "0.5"
      ],
      "text/plain": [
       "[1] 0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#testing accuracy\n",
    "testerr =  1- (sum(diag((confusion_mat_test[1:2,1:2]))) /  confusion_mat_test[3,3])\n",
    "testerr\n",
    "\n",
    "acc_test= 1- testerr\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871726db",
   "metadata": {},
   "source": [
    "Error=Accuracy= 50%. Accuracy is not sufficiently good. The model performed poorly on the test data.\n",
    "It was not a good choice to employ classic logistic regression when we have a data set with less number of instances than features. Some of the features could not be employed while estimating the model, therefore the results may be misleading. It has got NA for the features when p>N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "037a68f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>-20.2803473677753</dd>\n",
       "\t<dt>`X. 1`</dt>\n",
       "\t\t<dd>-19663.516434797</dd>\n",
       "\t<dt>`X. 2`</dt>\n",
       "\t\t<dd>-6486.09495029657</dd>\n",
       "\t<dt>`X. 3`</dt>\n",
       "\t\t<dd>87934.0117269021</dd>\n",
       "\t<dt>`X. 4`</dt>\n",
       "\t\t<dd>-70383.6462543929</dd>\n",
       "\t<dt>`X. 5`</dt>\n",
       "\t\t<dd>14669.4097678722</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] -20.2803473677753\n",
       "\\item[`X. 1`] -19663.516434797\n",
       "\\item[`X. 2`] -6486.09495029657\n",
       "\\item[`X. 3`] 87934.0117269021\n",
       "\\item[`X. 4`] -70383.6462543929\n",
       "\\item[`X. 5`] 14669.4097678722\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   -20.2803473677753`X. 1`\n",
       ":   -19663.516434797`X. 2`\n",
       ":   -6486.09495029657`X. 3`\n",
       ":   87934.0117269021`X. 4`\n",
       ":   -70383.6462543929`X. 5`\n",
       ":   14669.4097678722\n",
       "\n"
      ],
      "text/plain": [
       " (Intercept)       `X. 1`       `X. 2`       `X. 3`       `X. 4`       `X. 5` \n",
       "   -20.28035 -19663.51643  -6486.09495  87934.01173 -70383.64625  14669.40977 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>`Z. 310`</dt>\n",
       "\t\t<dd>&lt;NA&gt;</dd>\n",
       "\t<dt>`Z. 311`</dt>\n",
       "\t\t<dd>&lt;NA&gt;</dd>\n",
       "\t<dt>`Z. 312`</dt>\n",
       "\t\t<dd>&lt;NA&gt;</dd>\n",
       "\t<dt>`Z. 313`</dt>\n",
       "\t\t<dd>&lt;NA&gt;</dd>\n",
       "\t<dt>`Z. 314`</dt>\n",
       "\t\t<dd>&lt;NA&gt;</dd>\n",
       "\t<dt>`Z. 315`</dt>\n",
       "\t\t<dd>&lt;NA&gt;</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[`Z. 310`] <NA>\n",
       "\\item[`Z. 311`] <NA>\n",
       "\\item[`Z. 312`] <NA>\n",
       "\\item[`Z. 313`] <NA>\n",
       "\\item[`Z. 314`] <NA>\n",
       "\\item[`Z. 315`] <NA>\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "`Z. 310`\n",
       ":   &lt;NA&gt;`Z. 311`\n",
       ":   &lt;NA&gt;`Z. 312`\n",
       ":   &lt;NA&gt;`Z. 313`\n",
       ":   &lt;NA&gt;`Z. 314`\n",
       ":   &lt;NA&gt;`Z. 315`\n",
       ":   &lt;NA&gt;\n",
       "\n"
      ],
      "text/plain": [
       "`Z. 310` `Z. 311` `Z. 312` `Z. 313` `Z. 314` `Z. 315` \n",
       "      NA       NA       NA       NA       NA       NA "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(coef(log_reg))\n",
    "tail(coef(log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e7439",
   "metadata": {},
   "source": [
    "#### Use glmnet without lamdba (penalities) s=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afcfd6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use glmnet without lamdba (penalities) s=0\n",
    "#train on trainng data\n",
    "library(\"glmnet\")\n",
    "library(\"dplyr\")\n",
    "log_reg1=glmnet(as.matrix(c_train[,-1]),c_train$Ges_Class,family='binomial')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72e28d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time difference of 0.3740809 secs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use the model to predict test data\n",
    "#set lambda specificily to \"0\"\n",
    "start.time <- Sys.time()\n",
    "predicted_prob_test1 <-  predict(log_reg1,as.matrix(c_test[,-1]),type='response', s= 0)\n",
    "prediction_test1 <- as.integer(predicted_prob_test1 > ratio)\n",
    "end.time <- Sys.time()\n",
    "time.taken <- end.time - start.time\n",
    "time.taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fce3c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>0</th><th scope=col>1</th><th scope=col>Sum</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>0</th><td>2923</td><td>205 </td><td>3128</td></tr>\n",
       "\t<tr><th scope=row>1</th><td>  58</td><td>396 </td><td> 454</td></tr>\n",
       "\t<tr><th scope=row>Sum</th><td>2981</td><td>601 </td><td>3582</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & 0 & 1 & Sum\\\\\n",
       "\\hline\n",
       "\t0 & 2923 & 205  & 3128\\\\\n",
       "\t1 &   58 & 396  &  454\\\\\n",
       "\tSum & 2981 & 601  & 3582\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 0 | 1 | Sum |\n",
       "|---|---|---|---|\n",
       "| 0 | 2923 | 205  | 3128 |\n",
       "| 1 |   58 | 396  |  454 |\n",
       "| Sum | 2981 | 601  | 3582 |\n",
       "\n"
      ],
      "text/plain": [
       "     prediction_test1\n",
       "      0    1   Sum \n",
       "  0   2923 205 3128\n",
       "  1     58 396  454\n",
       "  Sum 2981 601 3582"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat_test1 <- addmargins(table(c_test$Ges_Class, prediction_test1))\n",
    "\n",
    "conf_mat_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57786564",
   "metadata": {},
   "source": [
    "396 of the total 454 class3 instances are predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0fc8999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0734226689000559"
      ],
      "text/latex": [
       "0.0734226689000559"
      ],
      "text/markdown": [
       "0.0734226689000559"
      ],
      "text/plain": [
       "[1] 0.07342267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.926577331099944"
      ],
      "text/latex": [
       "0.926577331099944"
      ],
      "text/markdown": [
       "0.926577331099944"
      ],
      "text/plain": [
       "[1] 0.9265773"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testerr1 =  1- (sum(diag((conf_mat_test1[1:2,1:2]))) /  conf_mat_test1[3,3])\n",
    "testerr1\n",
    "acc1 = 1- testerr1\n",
    "acc1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f54165",
   "metadata": {},
   "source": [
    "The accuracy is 92%. It took 0.3740809 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7376db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "                    1\n",
       "(Intercept) -6.550843\n",
       "X. 1         .       \n",
       "X. 2         .       \n",
       "X. 3         .       \n",
       "X. 4         .       \n",
       "X. 5         .       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "               1\n",
       "Z. 310 .        \n",
       "Z. 311 .        \n",
       "Z. 312 .        \n",
       "Z. 313 .        \n",
       "Z. 314 .        \n",
       "Z. 315 0.1848655"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(coef(log_reg1, s=0))\n",
    "tail(coef(log_reg1, s=0))\n",
    "#even the last feature got evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87dbba00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "57"
      ],
      "text/latex": [
       "57"
      ],
      "text/markdown": [
       "57"
      ],
      "text/plain": [
       "[1] 57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#total non zero coeff + 1 intercept\n",
    "howmanylog= sum(ifelse(coef(log_reg1,s=0) != 0 , 1,0))\n",
    "howmanylog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb41b42b",
   "metadata": {},
   "source": [
    "56 features + 1 intercept were employed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df24a5",
   "metadata": {},
   "source": [
    "### 2b) An advantage of logistic regression is related to the interpretability however when we have large number of features together with a method without penalization, it is harder to interpret the results. Therefore, an alternative way is to train a logistic regression model with lasso penalties. This will require you setting of penalization term (namely lambda). Use 10-fold cross-validation to determine your ideal lambda level based on binomial deviance. This is also referred to as logistic loss. If you are using “glmnet” package in R, “type.measure” can be set to “deviance” which is the default value. Once you determine your best lambda value using 10-fold cross-validation, perform classification on test data similar to part a and compare your results. Comment on the regression coefficients. Is there any interesting information? Try to interpret the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8624e293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'data.frame'"
      ],
      "text/latex": [
       "'data.frame'"
      ],
      "text/markdown": [
       "'data.frame'"
      ],
      "text/plain": [
       "[1] \"data.frame\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'matrix'"
      ],
      "text/latex": [
       "'matrix'"
      ],
      "text/markdown": [
       "'matrix'"
      ],
      "text/plain": [
       "[1] \"matrix\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######penalize###########\n",
    "#α=1 is lasso regression (default in glmnet)\n",
    "library(\"glmnet\")\n",
    "library(\"dplyr\")\n",
    "class(c_train)\n",
    "#make matrix\n",
    "class_mat_train = as.matrix(c_train[,-1])\n",
    "class(class_mat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de84d557",
   "metadata": {},
   "source": [
    "10 fold cross validation is used.\n",
    "The used measure is \"deviance\"\n",
    "Get the lambda values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6351421d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:  cv.glmnet(x = class_mat_train, y = c_train$Ges_Class, type.measure = \"deviance\",      nfolds = 10, family = \"binomial\") \n",
       "\n",
       "Measure: Binomial Deviance \n",
       "\n",
       "      Lambda Index Measure      SE Nonzero\n",
       "min 0.003889    79  0.1970 0.02438      37\n",
       "1se 0.011877    55  0.2199 0.02116      29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cvlogfit=cv.glmnet(class_mat_train,c_train$Ges_Class,family='binomial',nfolds=10, type.measure = \"deviance\")\n",
    "cvlogfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b07e0659",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\nSIADigQ4oEiAA4oEOPgfnT0cmkWH4WsAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(cvlogfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e7c87",
   "metadata": {},
   "source": [
    "The argmin lambda would give about ~ 36 ~ 38 non-zero coffieicents with miminal binomial deviance. The argmin labmda is given below as lambda min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "05e4a77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:  cv.glmnet(x = class_mat_train, y = c_train$Ges_Class, type.measure = \"deviance\",      nfolds = 10, family = \"binomial\") \n",
       "\n",
       "Measure: Binomial Deviance \n",
       "\n",
       "      Lambda Index Measure      SE Nonzero\n",
       "min 0.003712    80  0.2002 0.02463      37\n",
       "1se 0.011877    55  0.2238 0.02238      29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cvlogfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57967a4",
   "metadata": {},
   "source": [
    "#### 2b) Comment on the regression coefficients. Is there any interesting information? Try to interpret the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23fdf19",
   "metadata": {},
   "source": [
    "Before, we had 3*315 = 945 features, we reduced them. \n",
    "Now we have 37 nonzero coefficients.\n",
    "Now let's see, in which indexes the non-zero coefficients occur.\n",
    "Plot one instance from each class as time series, and try to catch where class#3 is distinct the most.\n",
    "In terms of distance from one the other, we may see the part (in index) where the class#3 is the most distinct from the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f46eaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>-5.34675761649471</dd>\n",
       "\t<dt>X. 14</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>X. 15</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>X. 17</dt>\n",
       "\t\t<dd>-0.0823919490841221</dd>\n",
       "\t<dt>Y. 11</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>Y. 12</dt>\n",
       "\t\t<dd>-0.293850556016789</dd>\n",
       "\t<dt>Y. 24</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>Z. 1</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>Z. 249</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>Z. 257</dt>\n",
       "\t\t<dd>-0.128888843561992</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] -5.34675761649471\n",
       "\\item[X. 14] 0\n",
       "\\item[X. 15] 0\n",
       "\\item[X. 17] -0.0823919490841221\n",
       "\\item[Y. 11] 0\n",
       "\\item[Y. 12] -0.293850556016789\n",
       "\\item[Y. 24] 0\n",
       "\\item[Z. 1] 0\n",
       "\\item[Z. 249] 0\n",
       "\\item[Z. 257] -0.128888843561992\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   -5.34675761649471X. 14\n",
       ":   0X. 15\n",
       ":   0X. 17\n",
       ":   -0.0823919490841221Y. 11\n",
       ":   0Y. 12\n",
       ":   -0.293850556016789Y. 24\n",
       ":   0Z. 1\n",
       ":   0Z. 249\n",
       ":   0Z. 257\n",
       ":   -0.128888843561992\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)       X. 14       X. 15       X. 17       Y. 11       Y. 12 \n",
       "-5.34675762  0.00000000  0.00000000 -0.08239195  0.00000000 -0.29385056 \n",
       "      Y. 24        Z. 1      Z. 249      Z. 257 \n",
       " 0.00000000  0.00000000  0.00000000 -0.12888884 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show several coefficients for labbda.min\n",
    "coef(cvlogfit,s=\"lambda.min\")[c(1,15,16,18,327,328,340,632,880,888),1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "69c820cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>946</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 946\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 946\n",
       "2. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 946   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(coef(cvlogfit,s=\"lambda.min\"))\n",
    "#945 features + 1 intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "842b575e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "20"
      ],
      "text/latex": [
       "20"
      ],
      "text/markdown": [
       "20"
      ],
      "text/plain": [
       "[1] 20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "10"
      ],
      "text/latex": [
       "10"
      ],
      "text/markdown": [
       "10"
      ],
      "text/plain": [
       "[1] 10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "7"
      ],
      "text/latex": [
       "7"
      ],
      "text/markdown": [
       "7"
      ],
      "text/plain": [
       "[1] 7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now let's see, in which indexes the non-zero coefficients occur.\n",
    "howmanyx= sum(ifelse(coef(cvlogfit,s=\"lambda.min\")[2:316,] != 0 , 1,0))\n",
    "howmanyy= sum(ifelse(coef(cvlogfit,s=\"lambda.min\")[317:631,] != 0 , 1,0))\n",
    "howmanyz= sum(ifelse(coef(cvlogfit,s=\"lambda.min\")[632:946,] != 0 , 1,0))\n",
    "howmanyx\n",
    "howmanyy\n",
    "howmanyz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04358047",
   "metadata": {},
   "source": [
    "20 x features, 10 y features, 7 z features have non-zero coefficients. The others were eliminated ( penalized and got 0 coeff.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3cd59772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "38"
      ],
      "text/latex": [
       "38"
      ],
      "text/markdown": [
       "38"
      ],
      "text/plain": [
       "[1] 38"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#total non zero coeff + 1 intercept\n",
    "howmany = howmanyx +howmanyy + howmanyz +1 \n",
    "howmany\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d3153a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Ges_Class</th><th scope=col>X. 1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>6          </td><td>-0.42019517</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>5          </td><td> 1.78273070</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>3          </td><td>-0.06635733</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>7          </td><td> 1.60010472</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>4          </td><td> 0.27606638</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>1          </td><td>-0.97948722</td></tr>\n",
       "\t<tr><th scope=row>20</th><td>2          </td><td> 0.08202627</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>8          </td><td>-0.64847764</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & Ges\\_Class & X. 1\\\\\n",
       "\\hline\n",
       "\t1 & 6           & -0.42019517\\\\\n",
       "\t2 & 5           &  1.78273070\\\\\n",
       "\t4 & 3           & -0.06635733\\\\\n",
       "\t7 & 7           &  1.60010472\\\\\n",
       "\t8 & 4           &  0.27606638\\\\\n",
       "\t11 & 1           & -0.97948722\\\\\n",
       "\t20 & 2           &  0.08202627\\\\\n",
       "\t21 & 8           & -0.64847764\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Ges_Class | X. 1 |\n",
       "|---|---|---|\n",
       "| 1 | 6           | -0.42019517 |\n",
       "| 2 | 5           |  1.78273070 |\n",
       "| 4 | 3           | -0.06635733 |\n",
       "| 7 | 7           |  1.60010472 |\n",
       "| 8 | 4           |  0.27606638 |\n",
       "| 11 | 1           | -0.97948722 |\n",
       "| 20 | 2           |  0.08202627 |\n",
       "| 21 | 8           | -0.64847764 |\n",
       "\n"
      ],
      "text/plain": [
       "   Ges_Class X. 1       \n",
       "1  6         -0.42019517\n",
       "2  5          1.78273070\n",
       "4  3         -0.06635733\n",
       "7  7          1.60010472\n",
       "8  4          0.27606638\n",
       "11 1         -0.97948722\n",
       "20 2          0.08202627\n",
       "21 8         -0.64847764"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#########plot\n",
    "#Plot one instance from each class as time series, and try to catch where class#3 is distinct the most.\n",
    "#In terms of distance from one the other, we may see the part (in index) where \n",
    "#the class#3 is the most distinct from the others.\n",
    "\n",
    "#the acceleration data for classes in x1-x2----y1-y2----z1-z2 format\n",
    "#get a random instance of ech class\n",
    "#use Scaled_Train_Data_Conc data\n",
    "Scaled_Train_Data_Conc[c(1,2,4,7,8,11,20,21),1:2]\n",
    "#index 1-gesture6\n",
    "#index 2-gesture5\n",
    "#index 4-gesture3##\n",
    "#index 7-gesture7\n",
    "#index 8-gesture4\n",
    "#index 11-gesture1\n",
    "#index 20-gesture2\n",
    "#index 21-gesture8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "41b6a744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>-5.34675761649471</dd>\n",
       "\t<dt>X. 14</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>X. 15</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>X. 17</dt>\n",
       "\t\t<dd>-0.0823919490841221</dd>\n",
       "\t<dt>Y. 11</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>Y. 12</dt>\n",
       "\t\t<dd>-0.293850556016789</dd>\n",
       "\t<dt>Y. 24</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>Z. 1</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>Z. 249</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>Z. 257</dt>\n",
       "\t\t<dd>-0.128888843561992</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] -5.34675761649471\n",
       "\\item[X. 14] 0\n",
       "\\item[X. 15] 0\n",
       "\\item[X. 17] -0.0823919490841221\n",
       "\\item[Y. 11] 0\n",
       "\\item[Y. 12] -0.293850556016789\n",
       "\\item[Y. 24] 0\n",
       "\\item[Z. 1] 0\n",
       "\\item[Z. 249] 0\n",
       "\\item[Z. 257] -0.128888843561992\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   -5.34675761649471X. 14\n",
       ":   0X. 15\n",
       ":   0X. 17\n",
       ":   -0.0823919490841221Y. 11\n",
       ":   0Y. 12\n",
       ":   -0.293850556016789Y. 24\n",
       ":   0Z. 1\n",
       ":   0Z. 249\n",
       ":   0Z. 257\n",
       ":   -0.128888843561992\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)       X. 14       X. 15       X. 17       Y. 11       Y. 12 \n",
       "-5.34675762  0.00000000  0.00000000 -0.08239195  0.00000000 -0.29385056 \n",
       "      Y. 24        Z. 1      Z. 249      Z. 257 \n",
       " 0.00000000  0.00000000  0.00000000 -0.12888884 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\nIYhCAAlBFAJICKIQQEIQhQASgijkf7Dfzcv3oxLnAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title \"Training data in timeseries\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#now plot\n",
    "#this is class#3\n",
    "plot( c(1:945),Scaled_Train_Data_Conc[4,-1],type=\"l\", xlab=\"Index\", col=\"red\",ylab=\"\", main =\"Training data in timeseries\")\n",
    "#plot the others\n",
    "for (i in c(1,2,7,8,11,20,21))   \n",
    "{\n",
    "  points ( c(1:945),Scaled_Train_Data_Conc[i,-1],type=\"l\", xlab=\"Index\", col=\"beige\") \n",
    " \n",
    "}\n",
    "\n",
    "#add a vertical line for which the coeffieicients a nonzero, for instance add a line to x=17 y=12 z= 257 ..\n",
    "coef(cvlogfit,s=\"lambda.min\")[c(1,15,16,18,327,328,340,632,880,888),1]\n",
    "\n",
    "no=0\n",
    "for (i in 2:946) {\n",
    "if (coef(cvlogfit,s=\"lambda.min\")[i,1] != 0) \n",
    "{#print ( coef(cvlogfit,s=\"lambda.min\")[i,1]) #show which\n",
    " #print(i)\n",
    "  no = no+1\n",
    "  abline ( v  =  i-1 , col = \"black\")} \n",
    "  # minus 1st index intercept,indexofcoord=i-1, where intercept(i=1),x1... x(index)=i-1,...x315, y1,...z1,...z315\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "94e80c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "37"
      ],
      "text/latex": [
       "37"
      ],
      "text/markdown": [
       "37"
      ],
      "text/plain": [
       "[1] 37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#index: first 315 for x, next 315 for y, the last 315 for z\n",
    "# no= number of nonzero coeff (excluding intercept, only for x1,x2,,z314,z315)\n",
    "no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b2501c",
   "metadata": {},
   "source": [
    "The number effective features reduced to 37 (+1 intercept).\n",
    "\n",
    "On the plot, we can see that nonzero coefficents are in between x235-x336 mostly, there is a few nonzero for y and z has even less effective coordinate values.\n",
    "\n",
    "Xcoordinates have the most affect on the results. This result is in-line with our previous assumption on weighting the distances on each x-y-x coordinate seperately. For instance, here, x should have gotten more weight. It makes sense since class#3 is a straight line lying on the x axis.\n",
    "\n",
    "On the plot we can compare the behavior of  class#3  to the others. It is quite hard to capture the difference, but, Class#3 behavior seem to differ from the other classes in terms of the xcord values the most, in between ~ x235-x336. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f29622",
   "metadata": {},
   "source": [
    "#### Test on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "33426ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time difference of 0.05702496 secs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>0</th><th scope=col>1</th><th scope=col>Sum</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>0</th><td>2897</td><td>231 </td><td>3128</td></tr>\n",
       "\t<tr><th scope=row>1</th><td>  42</td><td>412 </td><td> 454</td></tr>\n",
       "\t<tr><th scope=row>Sum</th><td>2939</td><td>643 </td><td>3582</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & 0 & 1 & Sum\\\\\n",
       "\\hline\n",
       "\t0 & 2897 & 231  & 3128\\\\\n",
       "\t1 &   42 & 412  &  454\\\\\n",
       "\tSum & 2939 & 643  & 3582\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 0 | 1 | Sum |\n",
       "|---|---|---|---|\n",
       "| 0 | 2897 | 231  | 3128 |\n",
       "| 1 |   42 | 412  |  454 |\n",
       "| Sum | 2939 | 643  | 3582 |\n",
       "\n"
      ],
      "text/plain": [
       "     pen_pred_test\n",
       "      0    1   Sum \n",
       "  0   2897 231 3128\n",
       "  1     42 412  454\n",
       "  Sum 2939 643 3582"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test on test data\n",
    "class_mat_test = as.matrix(c_test[,-1])\n",
    "#on test data\n",
    "start.time <- Sys.time()\n",
    "\n",
    "pen_prob_test <-  predict(cvlogfit,class_mat_test,type='response',s='lambda.min')\n",
    "#pen_prob_test\n",
    "pen_pred_test <- as.integer(pen_prob_test > ratio)\n",
    "\n",
    "end.time <- Sys.time()\n",
    "time.taken <- end.time - start.time\n",
    "time.taken\n",
    "\n",
    "pen_confusion_mat_test <- addmargins(table(c_test$Ges_Class, pen_pred_test))\n",
    "\n",
    "pen_confusion_mat_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c602e",
   "metadata": {},
   "source": [
    "The  model predicted 412 of the 454 class#3 correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bd0a6852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       1            \n",
       " Min.   :0.0000014  \n",
       " 1st Qu.:0.0004345  \n",
       " Median :0.0026884  \n",
       " Mean   :0.1162499  \n",
       " 3rd Qu.:0.0274760  \n",
       " Max.   :0.9966285  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(pen_prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2f7c5879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.076214405360134"
      ],
      "text/latex": [
       "0.076214405360134"
      ],
      "text/markdown": [
       "0.076214405360134"
      ],
      "text/plain": [
       "[1] 0.07621441"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.923785594639866"
      ],
      "text/latex": [
       "0.923785594639866"
      ],
      "text/markdown": [
       "0.923785594639866"
      ],
      "text/plain": [
       "[1] 0.9237856"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#testing error & accuracy\n",
    "pentesterr =  1- (sum(diag((pen_confusion_mat_test[1:2,1:2]))) /  pen_confusion_mat_test[3,3])\n",
    "pentesterr \n",
    "\n",
    "pen_acc_test= 1- pentesterr\n",
    "pen_acc_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce169b9",
   "metadata": {},
   "source": [
    "Accuracy = 92.4 %. It is significantly increased compared to the first model without penalties. \n",
    "Overfitting is prevented since not all of the features were employed in the model now, some were penalized. Model complexity is significantly reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2883c5",
   "metadata": {},
   "source": [
    "### 2c) You are expected to transform your training data to distance information (i.e. Nby N matrix). Note that you need to perform a similar transformation to your test data. In other words, you need to calculate the distance of each test instance to training instance to obtain a distance based representation for your test data. This will be an Ntest by N matrix (Ntest refers to the number of test instances) where each entry (i,j) refers to the distance of test time series i to the training time series j. You can use Euclidean distance as your distance measure. Perform the same training and test strategy as in part b but use the distances as your new feature matrices. Comment on the regression coefficients. What do they imply under this new representation setting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5dcb2b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X. 1</th><th scope=col>X. 2</th><th scope=col>X. 3</th><th scope=col>X. 4</th><th scope=col>X. 5</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-0.42019517</td><td>-0.42002489</td><td>-0.41967767</td><td>-0.41931952</td><td>-0.41912939</td></tr>\n",
       "\t<tr><td> 1.78273070</td><td> 1.78260929</td><td> 1.78213720</td><td> 1.78148436</td><td> 1.78034280</td></tr>\n",
       "\t<tr><td> 0.67556070</td><td> 0.67558589</td><td> 0.67552558</td><td> 0.67538086</td><td> 0.67490859</td></tr>\n",
       "\t<tr><td>-0.06635733</td><td>-0.06623391</td><td>-0.06601829</td><td>-0.06582253</td><td>-0.06584629</td></tr>\n",
       "\t<tr><td> 1.39465049</td><td> 1.39458047</td><td> 1.39425271</td><td> 1.39377798</td><td> 1.39287102</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllll}\n",
       " X. 1 & X. 2 & X. 3 & X. 4 & X. 5\\\\\n",
       "\\hline\n",
       "\t -0.42019517 & -0.42002489 & -0.41967767 & -0.41931952 & -0.41912939\\\\\n",
       "\t  1.78273070 &  1.78260929 &  1.78213720 &  1.78148436 &  1.78034280\\\\\n",
       "\t  0.67556070 &  0.67558589 &  0.67552558 &  0.67538086 &  0.67490859\\\\\n",
       "\t -0.06635733 & -0.06623391 & -0.06601829 & -0.06582253 & -0.06584629\\\\\n",
       "\t  1.39465049 &  1.39458047 &  1.39425271 &  1.39377798 &  1.39287102\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| X. 1 | X. 2 | X. 3 | X. 4 | X. 5 |\n",
       "|---|---|---|---|---|\n",
       "| -0.42019517 | -0.42002489 | -0.41967767 | -0.41931952 | -0.41912939 |\n",
       "|  1.78273070 |  1.78260929 |  1.78213720 |  1.78148436 |  1.78034280 |\n",
       "|  0.67556070 |  0.67558589 |  0.67552558 |  0.67538086 |  0.67490859 |\n",
       "| -0.06635733 | -0.06623391 | -0.06601829 | -0.06582253 | -0.06584629 |\n",
       "|  1.39465049 |  1.39458047 |  1.39425271 |  1.39377798 |  1.39287102 |\n",
       "\n"
      ],
      "text/plain": [
       "     X. 1        X. 2        X. 3        X. 4        X. 5       \n",
       "[1,] -0.42019517 -0.42002489 -0.41967767 -0.41931952 -0.41912939\n",
       "[2,]  1.78273070  1.78260929  1.78213720  1.78148436  1.78034280\n",
       "[3,]  0.67556070  0.67558589  0.67552558  0.67538086  0.67490859\n",
       "[4,] -0.06635733 -0.06623391 -0.06601829 -0.06582253 -0.06584629\n",
       "[5,]  1.39465049  1.39458047  1.39425271  1.39377798  1.39287102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X. 1</th><th scope=col>X. 2</th><th scope=col>X. 3</th><th scope=col>X. 4</th><th scope=col>X. 5</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1.7528041</td><td> 1.7534430</td><td> 1.7538109</td><td> 1.7542993</td><td> 1.7548017</td></tr>\n",
       "\t<tr><td>-0.1433734</td><td>-0.1438205</td><td>-0.1440569</td><td>-0.1439606</td><td>-0.1436661</td></tr>\n",
       "\t<tr><td> 1.6949938</td><td> 1.7187370</td><td> 1.7306662</td><td> 1.7542993</td><td> 1.7663777</td></tr>\n",
       "\t<tr><td> 1.4521906</td><td> 1.4526574</td><td> 1.4529294</td><td> 1.4533557</td><td> 1.4538250</td></tr>\n",
       "\t<tr><td> 1.4521906</td><td> 1.4526574</td><td> 1.4529294</td><td> 1.4533557</td><td> 1.4538250</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllll}\n",
       " X. 1 & X. 2 & X. 3 & X. 4 & X. 5\\\\\n",
       "\\hline\n",
       "\t  1.7528041 &  1.7534430 &  1.7538109 &  1.7542993 &  1.7548017\\\\\n",
       "\t -0.1433734 & -0.1438205 & -0.1440569 & -0.1439606 & -0.1436661\\\\\n",
       "\t  1.6949938 &  1.7187370 &  1.7306662 &  1.7542993 &  1.7663777\\\\\n",
       "\t  1.4521906 &  1.4526574 &  1.4529294 &  1.4533557 &  1.4538250\\\\\n",
       "\t  1.4521906 &  1.4526574 &  1.4529294 &  1.4533557 &  1.4538250\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| X. 1 | X. 2 | X. 3 | X. 4 | X. 5 |\n",
       "|---|---|---|---|---|\n",
       "|  1.7528041 |  1.7534430 |  1.7538109 |  1.7542993 |  1.7548017 |\n",
       "| -0.1433734 | -0.1438205 | -0.1440569 | -0.1439606 | -0.1436661 |\n",
       "|  1.6949938 |  1.7187370 |  1.7306662 |  1.7542993 |  1.7663777 |\n",
       "|  1.4521906 |  1.4526574 |  1.4529294 |  1.4533557 |  1.4538250 |\n",
       "|  1.4521906 |  1.4526574 |  1.4529294 |  1.4533557 |  1.4538250 |\n",
       "\n"
      ],
      "text/plain": [
       "     X. 1       X. 2       X. 3       X. 4       X. 5      \n",
       "[1,]  1.7528041  1.7534430  1.7538109  1.7542993  1.7548017\n",
       "[2,] -0.1433734 -0.1438205 -0.1440569 -0.1439606 -0.1436661\n",
       "[3,]  1.6949938  1.7187370  1.7306662  1.7542993  1.7663777\n",
       "[4,]  1.4521906  1.4526574  1.4529294  1.4533557  1.4538250\n",
       "[5,]  1.4521906  1.4526574  1.4529294  1.4533557  1.4538250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>X. 1</th><td>-0.4201952 </td><td>1.782731   </td><td>0.6755607  </td><td>-0.06635733</td><td>1.394650   </td></tr>\n",
       "\t<tr><th scope=row>X. 2</th><td>-0.4200249 </td><td>1.782609   </td><td>0.6755859  </td><td>-0.06623391</td><td>1.394580   </td></tr>\n",
       "\t<tr><th scope=row>X. 3</th><td>-0.4196777 </td><td>1.782137   </td><td>0.6755256  </td><td>-0.06601829</td><td>1.394253   </td></tr>\n",
       "\t<tr><th scope=row>X. 4</th><td>-0.4193195 </td><td>1.781484   </td><td>0.6753809  </td><td>-0.06582253</td><td>1.393778   </td></tr>\n",
       "\t<tr><th scope=row>X. 5</th><td>-0.4191294 </td><td>1.780343   </td><td>0.6749086  </td><td>-0.06584629</td><td>1.392871   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "\tX. 1 & -0.4201952  & 1.782731    & 0.6755607   & -0.06635733 & 1.394650   \\\\\n",
       "\tX. 2 & -0.4200249  & 1.782609    & 0.6755859   & -0.06623391 & 1.394580   \\\\\n",
       "\tX. 3 & -0.4196777  & 1.782137    & 0.6755256   & -0.06601829 & 1.394253   \\\\\n",
       "\tX. 4 & -0.4193195  & 1.781484    & 0.6753809   & -0.06582253 & 1.393778   \\\\\n",
       "\tX. 5 & -0.4191294  & 1.780343    & 0.6749086   & -0.06584629 & 1.392871   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| X. 1 | -0.4201952  | 1.782731    | 0.6755607   | -0.06635733 | 1.394650    |\n",
       "| X. 2 | -0.4200249  | 1.782609    | 0.6755859   | -0.06623391 | 1.394580    |\n",
       "| X. 3 | -0.4196777  | 1.782137    | 0.6755256   | -0.06601829 | 1.394253    |\n",
       "| X. 4 | -0.4193195  | 1.781484    | 0.6753809   | -0.06582253 | 1.393778    |\n",
       "| X. 5 | -0.4191294  | 1.780343    | 0.6749086   | -0.06584629 | 1.392871    |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]       [,2]     [,3]      [,4]        [,5]    \n",
       "X. 1 -0.4201952 1.782731 0.6755607 -0.06635733 1.394650\n",
       "X. 2 -0.4200249 1.782609 0.6755859 -0.06623391 1.394580\n",
       "X. 3 -0.4196777 1.782137 0.6755256 -0.06601829 1.394253\n",
       "X. 4 -0.4193195 1.781484 0.6753809 -0.06582253 1.393778\n",
       "X. 5 -0.4191294 1.780343 0.6749086 -0.06584629 1.392871"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>X. 1</th><td>1.752804  </td><td>-0.1433734</td><td>1.694994  </td><td>1.452191  </td><td>1.452191  </td></tr>\n",
       "\t<tr><th scope=row>X. 2</th><td>1.753443  </td><td>-0.1438205</td><td>1.718737  </td><td>1.452657  </td><td>1.452657  </td></tr>\n",
       "\t<tr><th scope=row>X. 3</th><td>1.753811  </td><td>-0.1440569</td><td>1.730666  </td><td>1.452929  </td><td>1.452929  </td></tr>\n",
       "\t<tr><th scope=row>X. 4</th><td>1.754299  </td><td>-0.1439606</td><td>1.754299  </td><td>1.453356  </td><td>1.453356  </td></tr>\n",
       "\t<tr><th scope=row>X. 5</th><td>1.754802  </td><td>-0.1436661</td><td>1.766378  </td><td>1.453825  </td><td>1.453825  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "\tX. 1 & 1.752804   & -0.1433734 & 1.694994   & 1.452191   & 1.452191  \\\\\n",
       "\tX. 2 & 1.753443   & -0.1438205 & 1.718737   & 1.452657   & 1.452657  \\\\\n",
       "\tX. 3 & 1.753811   & -0.1440569 & 1.730666   & 1.452929   & 1.452929  \\\\\n",
       "\tX. 4 & 1.754299   & -0.1439606 & 1.754299   & 1.453356   & 1.453356  \\\\\n",
       "\tX. 5 & 1.754802   & -0.1436661 & 1.766378   & 1.453825   & 1.453825  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| X. 1 | 1.752804   | -0.1433734 | 1.694994   | 1.452191   | 1.452191   |\n",
       "| X. 2 | 1.753443   | -0.1438205 | 1.718737   | 1.452657   | 1.452657   |\n",
       "| X. 3 | 1.753811   | -0.1440569 | 1.730666   | 1.452929   | 1.452929   |\n",
       "| X. 4 | 1.754299   | -0.1439606 | 1.754299   | 1.453356   | 1.453356   |\n",
       "| X. 5 | 1.754802   | -0.1436661 | 1.766378   | 1.453825   | 1.453825   |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     [,2]       [,3]     [,4]     [,5]    \n",
       "X. 1 1.752804 -0.1433734 1.694994 1.452191 1.452191\n",
       "X. 2 1.753443 -0.1438205 1.718737 1.452657 1.452657\n",
       "X. 3 1.753811 -0.1440569 1.730666 1.452929 1.452929\n",
       "X. 4 1.754299 -0.1439606 1.754299 1.453356 1.453356\n",
       "X. 5 1.754802 -0.1436661 1.766378 1.453825 1.453825"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###distance matrix based approach\n",
    "#we already have\n",
    "class_mat_train[1:5,1:5]\n",
    "class_mat_test [1:5,1:5]\n",
    "#get the transpose, put each the instances in vector from (without class info)\n",
    "tr_train = t(class_mat_train)\n",
    "tr_test = t(class_mat_test)\n",
    "#sample\n",
    "tr_train [1:5,1:5]\n",
    "tr_test [1:5,1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cf4f7634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>945</li>\n",
       "\t<li>896</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 945\n",
       "\\item 896\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 945\n",
       "2. 896\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 945 896"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>945</li>\n",
       "\t<li>3582</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 945\n",
       "\\item 3582\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 945\n",
       "2. 3582\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  945 3582"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check dim\n",
    "dim(tr_train)\n",
    "dim(tr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40732eb7",
   "metadata": {},
   "source": [
    "tr_train has N=896 instances each has a lenght of 945. 945*896 matrix\n",
    "\n",
    "tr_testhas Ntest=3582 instances each has a lenght of 945. 945*3582 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc1490de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate distance between training of each instance training/test and each instance of trainig\n",
    "\n",
    "dismat_train = matrix( nrow = ncol(tr_train), ncol = ncol(tr_train))\n",
    "dismat_tt = matrix( nrow = ncol(tr_test), ncol = ncol(tr_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a14ae0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td> 0.00000</td><td>51.55262</td><td>46.83241</td><td>50.69513</td><td>41.05373</td></tr>\n",
       "\t<tr><td>51.55262</td><td> 0.00000</td><td>26.51161</td><td>37.89787</td><td>34.45132</td></tr>\n",
       "\t<tr><td>46.83241</td><td>26.51161</td><td> 0.00000</td><td>44.05189</td><td>37.55521</td></tr>\n",
       "\t<tr><td>50.69513</td><td>37.89787</td><td>44.05189</td><td> 0.00000</td><td>46.61585</td></tr>\n",
       "\t<tr><td>41.05373</td><td>34.45132</td><td>37.55521</td><td>46.61585</td><td> 0.00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllll}\n",
       "\t  0.00000 & 51.55262 & 46.83241 & 50.69513 & 41.05373\\\\\n",
       "\t 51.55262 &  0.00000 & 26.51161 & 37.89787 & 34.45132\\\\\n",
       "\t 46.83241 & 26.51161 &  0.00000 & 44.05189 & 37.55521\\\\\n",
       "\t 50.69513 & 37.89787 & 44.05189 &  0.00000 & 46.61585\\\\\n",
       "\t 41.05373 & 34.45132 & 37.55521 & 46.61585 &  0.00000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "|  0.00000 | 51.55262 | 46.83241 | 50.69513 | 41.05373 |\n",
       "| 51.55262 |  0.00000 | 26.51161 | 37.89787 | 34.45132 |\n",
       "| 46.83241 | 26.51161 |  0.00000 | 44.05189 | 37.55521 |\n",
       "| 50.69513 | 37.89787 | 44.05189 |  0.00000 | 46.61585 |\n",
       "| 41.05373 | 34.45132 | 37.55521 | 46.61585 |  0.00000 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     [,2]     [,3]     [,4]     [,5]    \n",
       "[1,]  0.00000 51.55262 46.83241 50.69513 41.05373\n",
       "[2,] 51.55262  0.00000 26.51161 37.89787 34.45132\n",
       "[3,] 46.83241 26.51161  0.00000 44.05189 37.55521\n",
       "[4,] 50.69513 37.89787 44.05189  0.00000 46.61585\n",
       "[5,] 41.05373 34.45132 37.55521 46.61585  0.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compute on train data. dist: train to train\n",
    "\n",
    "for (i in 1:ncol(tr_train))\n",
    "{\n",
    "for (j in 1:ncol(tr_train))\n",
    "  {\n",
    "    \n",
    "dismat_train [i,j]  = sqrt(sum( (tr_train[,i] -  tr_train[,j])^2 ) )\n",
    "\n",
    "  } #end j\n",
    "} #end i\n",
    "\n",
    "\n",
    "dismat_train [1:5,1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d75749aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>896</li>\n",
       "\t<li>896</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 896\n",
       "\\item 896\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 896\n",
       "2. 896\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 896 896"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#distance between 1st instance and 4th is 50.69\n",
    "dim(dismat_train)\n",
    "#it is 896*896 N*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "97c028c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>51.95028</td><td>14.07490</td><td>28.94035</td><td>41.30975</td><td>35.94806</td></tr>\n",
       "\t<tr><td>35.19561</td><td>55.46713</td><td>55.68959</td><td>47.95484</td><td>46.19773</td></tr>\n",
       "\t<tr><td>42.20911</td><td>25.98261</td><td>36.41021</td><td>43.44508</td><td>29.70895</td></tr>\n",
       "\t<tr><td>42.99393</td><td>35.47328</td><td>44.19846</td><td>46.06910</td><td>26.01566</td></tr>\n",
       "\t<tr><td>50.10720</td><td>15.31215</td><td>16.65211</td><td>43.26090</td><td>35.28094</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllll}\n",
       "\t 51.95028 & 14.07490 & 28.94035 & 41.30975 & 35.94806\\\\\n",
       "\t 35.19561 & 55.46713 & 55.68959 & 47.95484 & 46.19773\\\\\n",
       "\t 42.20911 & 25.98261 & 36.41021 & 43.44508 & 29.70895\\\\\n",
       "\t 42.99393 & 35.47328 & 44.19846 & 46.06910 & 26.01566\\\\\n",
       "\t 50.10720 & 15.31215 & 16.65211 & 43.26090 & 35.28094\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 51.95028 | 14.07490 | 28.94035 | 41.30975 | 35.94806 |\n",
       "| 35.19561 | 55.46713 | 55.68959 | 47.95484 | 46.19773 |\n",
       "| 42.20911 | 25.98261 | 36.41021 | 43.44508 | 29.70895 |\n",
       "| 42.99393 | 35.47328 | 44.19846 | 46.06910 | 26.01566 |\n",
       "| 50.10720 | 15.31215 | 16.65211 | 43.26090 | 35.28094 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     [,2]     [,3]     [,4]     [,5]    \n",
       "[1,] 51.95028 14.07490 28.94035 41.30975 35.94806\n",
       "[2,] 35.19561 55.46713 55.68959 47.95484 46.19773\n",
       "[3,] 42.20911 25.98261 36.41021 43.44508 29.70895\n",
       "[4,] 42.99393 35.47328 44.19846 46.06910 26.01566\n",
       "[5,] 50.10720 15.31215 16.65211 43.26090 35.28094"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#calculate distance between  each instance of test and each instance of training \n",
    "\n",
    "for (i in 1:ncol(tr_test))\n",
    "{\n",
    "  for (j in 1:ncol(tr_train))\n",
    "  {\n",
    "    \n",
    "    dismat_tt [i,j]  = sqrt(sum( (tr_train[,j] -  tr_test[,i])^2 ) )\n",
    "    \n",
    "  } #end j\n",
    "} #end \n",
    "\n",
    "#sample train & test distance matrix\n",
    "dismat_tt [1:5,1:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "01f759f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>3582</li>\n",
       "\t<li>896</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3582\n",
       "\\item 896\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3582\n",
       "2. 896\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 3582  896"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#distance between 1st test instance and 4th training instance is 41.30\n",
    "dim(dismat_tt)\n",
    "#it is 3582*896 Ntest*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b11a754b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:  cv.glmnet(x = dismat_train, y = c_train$Ges_Class, type.measure = \"deviance\",      nfolds = 10, family = \"binomial\") \n",
       "\n",
       "Measure: Binomial Deviance \n",
       "\n",
       "      Lambda Index Measure      SE Nonzero\n",
       "min 0.002228    51  0.1213 0.02970      36\n",
       "1se 0.004273    44  0.1457 0.02979      24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use this distance info to build a model \n",
    "#use training distance matrix to build model with 10 folds\n",
    "\n",
    "cvfitds=cv.glmnet(dismat_train,c_train$Ges_Class,family='binomial',nfolds=10, type.measure = \"deviance\")\n",
    "cvfitds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ec557b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\ngg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(cvfitds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae5ec8",
   "metadata": {},
   "source": [
    "The minimizer lambda would give about ~ 36 non-zero cofficeints with miminal binomial deviance. The minimizer lambda is given below as lambda min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "21249d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:  cv.glmnet(x = dismat_train, y = c_train$Ges_Class, type.measure = \"deviance\",      nfolds = 10, family = \"binomial\") \n",
       "\n",
       "Measure: Binomial Deviance \n",
       "\n",
       "      Lambda Index Measure      SE Nonzero\n",
       "min 0.002228    51  0.1213 0.02970      36\n",
       "1se 0.004273    44  0.1457 0.02979      24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cvfitds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "40806bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>44.4459470129566</dd>\n",
       "\t<dt>V4</dt>\n",
       "\t\t<dd>-0.0535707675870164</dd>\n",
       "\t<dt>V5</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V112</dt>\n",
       "\t\t<dd>-0.0731223906632038</dd>\n",
       "\t<dt>V189</dt>\n",
       "\t\t<dd>-0.0810398027305592</dd>\n",
       "\t<dt>V199</dt>\n",
       "\t\t<dd>0</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 44.4459470129566\n",
       "\\item[V4] -0.0535707675870164\n",
       "\\item[V5] 0\n",
       "\\item[V112] -0.0731223906632038\n",
       "\\item[V189] -0.0810398027305592\n",
       "\\item[V199] 0\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   44.4459470129566V4\n",
       ":   -0.0535707675870164V5\n",
       ":   0V112\n",
       ":   -0.0731223906632038V189\n",
       ":   -0.0810398027305592V199\n",
       ":   0\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)          V4          V5        V112        V189        V199 \n",
       "44.44594701 -0.05357077  0.00000000 -0.07312239 -0.08103980  0.00000000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show sample coefficients\n",
    "coef(cvfitds,s=\"lambda.min\")[c(1,5,6,113,190,200),1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "87dad99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>897</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 897\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 897\n",
       "2. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 897   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "37"
      ],
      "text/latex": [
       "37"
      ],
      "text/markdown": [
       "37"
      ],
      "text/plain": [
       "[1] 37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(coef(cvfitds,s=\"lambda.min\"))\n",
    "howmanyds= sum(ifelse(coef(cvfitds,s=\"lambda.min\") != 0 , 1,0))\n",
    "\n",
    "#total non zero coeff + 1 intercept\n",
    "\n",
    "howmanyds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f1bfb",
   "metadata": {},
   "source": [
    "37 (36 feature +1 intercept) coefficients are non-zero as shown on the results of \"cvfitds\" as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6eb597",
   "metadata": {},
   "source": [
    "#### Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8f153f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time difference of 0.1050341 secs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>0</th><th scope=col>1</th><th scope=col>Sum</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>0</th><td>3006</td><td>122 </td><td>3128</td></tr>\n",
       "\t<tr><th scope=row>1</th><td>  23</td><td>431 </td><td> 454</td></tr>\n",
       "\t<tr><th scope=row>Sum</th><td>3029</td><td>553 </td><td>3582</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & 0 & 1 & Sum\\\\\n",
       "\\hline\n",
       "\t0 & 3006 & 122  & 3128\\\\\n",
       "\t1 &   23 & 431  &  454\\\\\n",
       "\tSum & 3029 & 553  & 3582\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 0 | 1 | Sum |\n",
       "|---|---|---|---|\n",
       "| 0 | 3006 | 122  | 3128 |\n",
       "| 1 |   23 | 431  |  454 |\n",
       "| Sum | 3029 | 553  | 3582 |\n",
       "\n"
      ],
      "text/plain": [
       "     ds_pred\n",
       "      0    1   Sum \n",
       "  0   3006 122 3128\n",
       "  1     23 431  454\n",
       "  Sum 3029 553 3582"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict on test\n",
    "start.time <- Sys.time()\n",
    "\n",
    "ds_prob <-  predict(cvfitds,dismat_tt,type='response', s=\"lambda.min\")\n",
    "ds_pred <- as.integer(ds_prob > ratio)\n",
    "\n",
    "end.time <- Sys.time()\n",
    "time.taken <- end.time - start.time\n",
    "time.taken\n",
    "\n",
    "ds_confusion_mat <- addmargins(table(c_test$Ges_Class, ds_pred ))\n",
    "\n",
    "ds_confusion_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2615e94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0404801786711334"
      ],
      "text/latex": [
       "0.0404801786711334"
      ],
      "text/markdown": [
       "0.0404801786711334"
      ],
      "text/plain": [
       "[1] 0.04048018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.959519821328867"
      ],
      "text/latex": [
       "0.959519821328867"
      ],
      "text/markdown": [
       "0.959519821328867"
      ],
      "text/plain": [
       "[1] 0.9595198"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#testing accuracy\n",
    "dserr =  1- (sum(diag((ds_confusion_mat[1:2,1:2]))) /  ds_confusion_mat[3,3])\n",
    "dserr\n",
    "\n",
    "dsacc= 1- dserr\n",
    "dsacc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffffdc7b",
   "metadata": {},
   "source": [
    "Almost 96 % accuracy is establihed. The accuracy is even better now, compared to the last two models. Inroduction of the nonlinear relationship information via Euclidean distances increased the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78e153",
   "metadata": {},
   "source": [
    "### 2c)Comment on the regression coefficients. What do they imply under this new representation setting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9048333c",
   "metadata": {},
   "source": [
    "The distances were treated as a feature matrix.Each feature held distance information, some sort of similarility of the time series.\n",
    "\n",
    "The model was build on the distance info between training instance i and training instance j. This was used as a similarity measure in order to capture the classification. The model provided regression coefficient for these new distance based features. \n",
    "\n",
    "It captured the time series relationship between ith and jth instance, based on how similar(~distant) they were. \n",
    "\n",
    "Then the model was used to predict the test instance's classes. It classified the instances in a way that it checked if the distance between test instance i and training instance j was \"similar\" to  the distance between the time series of the training data i and the time series of the training data j. This distance information established a classification model in the form of a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35ce55",
   "metadata": {},
   "source": [
    "### 2d) Provide an overall comparison on the results you obtain for each part (over all tasks). You can compare test accuracy of each alternative method you developed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639db16",
   "metadata": {},
   "source": [
    "#### Task1\n",
    "KNN was used to classify instances which is a non-parametric model.\n",
    "There is not much difference in terms of accuracy between the utilized distances.  \n",
    "\n",
    "#### Manhattan distance\n",
    "When the distance between instances (time series) was set to Manhattan, the k value is selected as 3.  Over 95 % accuracy is noted. The prediction took 26.51121 secs.\n",
    "#### Euclidean distance\n",
    "When distance was set to Euclidean, the k value is selected as 2.\n",
    "Almost 95 % acurracy is noted.\n",
    "We got a little bit higher accuracy with the model \"manhattan, K =3\"  than the other \"Euclidean K =2\".\n",
    "It took about 4 seconds to obtain the prediction results.\n",
    "\n",
    "#### Task2\n",
    "#### Logistic regression without penalties: \n",
    "Number of parameters were larger then the number of data points, which is not desirable. \n",
    "Training accuracy: 100 %.\n",
    "Accuracy on test data: 50 %.\n",
    "It overfits to the training data.\n",
    "Too many coefficients are utilized whereas the class#3 is a simple line of x-axis, we would expect the some of the info on the y-z axis to be not effective. Also, it was not a good choice to employ classic logistic regression when we have a data set with less number of instances than features. Some of the features could not be employed while estimating the model, therefore the results may be misleading. In 0.13376 seconds the prediction results were computed. When glmnet was used with lambda= 0 (penalty = 0), then  92% accuracy was noted. 56 features (with nonzero coefficients) + 1 intercept were employed.  It took 0.3740809 seconds.\n",
    "\n",
    "#### Lasso Regression, penalization is used:\n",
    "Before, we had 3*315 = 945 features, we reduced the number of non-zero coefficients with this approach.\n",
    "Now, we have 37 nonzero coefficients +1 intercept.This makes the model less complex and more interpretable.\n",
    "Most information comes from the x-coordinate indexes, which is reasonable consireing the shape of class#3. Many  of the features (coordinate information of the time series) were penalized and got 0 coefficients.\n",
    "Accuracy, in this case, is 92.4 %. It is significantly  increased compared to the first model without penalties.\n",
    "Overfitting is prevented since not all of the features were employed in the model now, some features were penalized and got 0 coefficients. Therefore, the model became less complex (which reduced the risk of overfitting) and it is easier to interpret.\n",
    "In 0.05702496 seconds the prediction results were computed, which is very fast, especially compared to knn.\n",
    "\n",
    "#### Using distance matrices as feature matrices:\n",
    "This model was created using the information about the distance between training instances i and j. Then, the distance between test instance i and training instance j was checked for \"similarity\" to establish a classification model in the form of a logistic regression model. For these new distance-based characteristics which could handle nonlinear relations, regression coefficients were extablished. Model had only 36+1 nonzero coefficient which is far less complicated than the first model in part a. Almost 96 % accuracy is establihed which is the best one we got. \n",
    "It took 0.1050341 seconds to obtain the prediction results.\n",
    "\n",
    "#### KNN is slow to predict. It has to keep track of all training data and find the neighbors in terms of distances which is a computational burden, whereas logistic regression can easily predict once the coefficients are tuned.\n",
    "#### KNN handled nonlinearity better by nature compared to the logistic regression model. Knn had higher accuracy without any extra modification. \n",
    "#### Logistic regression can be tuned to perform better with the introduction of penalties and the use of distance information which could keep nonlinear relations. The accuracy can be increased via these approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
